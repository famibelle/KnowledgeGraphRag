# ğŸ§  GraphRAG Knowledge Graph System

> **SystÃ¨me intelligent de questions-rÃ©ponses basÃ© sur un graphe de connaissances**
> 
> Combine Neo4j, OpenAI et FastAPI pour crÃ©er un systÃ¨me RAG (Retrieval Augmented Generation) avancÃ© avec recherche sÃ©mantique vectorielle et navigation contextuelle dans un graphe de connaissances.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![Neo4j](https://img.shields.io/badge/Neo4j-5.x-green.svg)](https://neo4j.com)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-red.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-Latest-orange.svg)](https://streamlit.io)

## ğŸš€ FonctionnalitÃ©s ClÃ©s

### ğŸ” **Recherche SÃ©mantique AvancÃ©e**
- **Embeddings vectoriels** via OpenAI (text-embedding-3-small, 1536 dimensions)
- **Index vectoriel Neo4j natif** pour une recherche sub-seconde
- **Seuils de similaritÃ© configurables** (0.7-0.9) pour Ã©viter les rÃ©sultats non pertinents
- **Support multilingue** optimisÃ© pour le franÃ§ais

### ğŸ•¸ï¸ **Graphe de Connaissances Intelligent**
- **Relations automatiques** entre chunks similaires (`RELATES_TO`)
- **Navigation sÃ©quentielle** dans les documents (`NEXT_CHUNK`, `PREVIOUS_CHUNK`)
- **Contexte enrichi** avec mÃ©tadonnÃ©es des documents
- **RequÃªtes Cypher flexibles** pour l'exploration avancÃ©e

### ğŸ“š **Ingestion Multi-Format**
- **Formats supportÃ©s** : PDF, Markdown, Word, Texte
- **DÃ©coupage intelligent** en chunks optimisÃ©s
- **CrÃ©ation automatique** du graphe de connaissances
- **Processing parallÃ¨le** pour les performances

### ğŸ§  **GÃ©nÃ©ration LLM Contextuelle**
- **Integration ChatGPT-3.5-turbo** pour les rÃ©ponses
- **RÃ©ponses contextualisÃ©es** basÃ©es sur les documents
- **Filtrage intelligent** pour Ã©viter les hallucinations
- **Recherche multi-documents** pour des requÃªtes complexes

## ğŸ—ï¸ Architecture Technique

### **Stack Technologique**

```mermaid
flowchart TB
    %% User Interface Layer
    subgraph "ğŸ¨ Interface Utilisateur"
        UI[Streamlit Frontend<br/>Port 8501]
        BROWSER[ğŸŒ Navigateur Web]
    end
    
    %% API Layer
    subgraph "âš¡ API Layer"
        API[FastAPI Backend<br/>Port 8000<br/>ThreadPoolExecutor]
        DOCS[ğŸ“Š Swagger/ReDoc<br/>Auto-generated]
    end
    
    %% External Services
    subgraph "ğŸ¤– Services IA"
        OPENAI_EMB[OpenAI Embeddings<br/>text-embedding-3-small<br/>1536 dimensions]
        OPENAI_LLM[OpenAI LLM<br/>GPT-3.5-turbo<br/>Response Generation]
    end
    
    %% Database Layer
    subgraph "ğŸ—„ï¸ Base de DonnÃ©es"
        NEO4J[Neo4j 5.x<br/>Graph + Vector DB]
        VECTOR_IDX[Vector Index<br/>GrahRAG<br/>Cosine Similarity]
        GRAPH_REL[Graph Relations<br/>NEXT/PREV/RELATES_TO]
    end
    
    %% Data Processing
    subgraph "ğŸ“Š Traitement Documents"
        INGEST[Document Ingestion<br/>PDF/MD/DOCX/TXT]
        CHUNK[Text Chunking<br/>RecursiveCharacterTextSplitter]
        EMBED[Embedding Generation<br/>Parallel Processing]
    end
    
    %% Connections
    BROWSER --> UI
    UI <--> API
    API --> DOCS
    
    API <--> OPENAI_EMB
    API <--> OPENAI_LLM
    API <--> NEO4J
    
    NEO4J --> VECTOR_IDX
    NEO4J --> GRAPH_REL
    
    API --> INGEST
    INGEST --> CHUNK
    CHUNK --> EMBED
    EMBED --> NEO4J
    
    %% Styling
    classDef frontend fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef backend fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    classDef ai fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef database fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef processing fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    class UI,BROWSER frontend
    class API,DOCS backend
    class OPENAI_EMB,OPENAI_LLM ai
    class NEO4J,VECTOR_IDX,GRAPH_REL database
    class INGEST,CHUNK,EMBED processing
```

**Architecture Technique :**
- **Frontend** : Streamlit (Python) - Interface web interactive
- **Backend** : FastAPI (Python async) - API REST haute performance
- **IA Services** : OpenAI (embeddings + LLM) - Traitement sÃ©mantique
- **Base de DonnÃ©es** : Neo4j 5.x - Graphe + index vectoriel natif
- **Performance** : ThreadPoolExecutor - Traitement parallÃ¨le optimisÃ©

### **ModÃ¨le de DonnÃ©es Neo4j**

```mermaid
graph TD
    %% Nodes
    D1[ğŸ“„ Document<br/>filename: string<br/>created_at: datetime<br/>file_extension: string<br/>chunk_count: integer]
    D2[ğŸ“„ Document<br/>autre_doc.pdf]
    
    C1[ğŸ“ Chunk<br/>text: string<br/>textEmbedding: vector 1536D<br/>chunkIndex: integer<br/>filename: string<br/>created_at: datetime]
    C2[ğŸ“ Chunk<br/>chunk_suivant]
    C3[ğŸ“ Chunk<br/>chunk_prÃ©cÃ©dent]
    C4[ğŸ“ Chunk<br/>chunk_similaire]
    C5[ğŸ“ Chunk<br/>autre_doc_chunk]
    
    %% Relations hiÃ©rarchiques
    D1 -.->|CONTAINS_CHUNK| C1
    D1 -.->|CONTAINS_CHUNK| C2
    D1 -.->|CONTAINS_CHUNK| C3
    D2 -.->|CONTAINS_CHUNK| C5
    
    %% Relations sÃ©quentielles (navigation dans le document)
    C3 -->|NEXT_CHUNK| C1
    C1 -->|NEXT_CHUNK| C2
    C1 -->|PREVIOUS_CHUNK| C3
    C2 -->|PREVIOUS_CHUNK| C1
    
    %% Relations sÃ©mantiques (inter et intra-documents)
    C1 -.->|RELATES_TO<br/>similarity: 0.87| C4
    C1 -.->|RELATES_TO<br/>similarity: 0.82| C5
    C4 -.->|RELATES_TO<br/>similarity: 0.85| C2
    
    %% Styling
    classDef documentNode fill:#e1f5fe,stroke:#01579b,stroke-width:2px
    classDef chunkNode fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
    classDef sequentialRel stroke:#2e7d32,stroke-width:3px
    classDef semanticRel stroke:#d84315,stroke-width:2px,stroke-dasharray: 5 5
    classDef hierarchicalRel stroke:#424242,stroke-width:2px,stroke-dasharray: 10 5
    
    class D1,D2 documentNode
    class C1,C2,C3,C4,C5 chunkNode
```

**LÃ©gende du ModÃ¨le :**
- ğŸ“„ **Document** : Fichier source ingÃ©rÃ© (PDF, MD, DOCX, TXT)
- ğŸ“ **Chunk** : Fragment de texte avec embedding vectoriel (1536D)
- **CONTAINS_CHUNK** : Relation hiÃ©rarchique document â†’ chunks
- **NEXT_CHUNK / PREVIOUS_CHUNK** : Navigation sÃ©quentielle dans le document
- **RELATES_TO** : Relations sÃ©mantiques inter/intra-documents (similarity > 0.8)

### **ğŸ” RequÃªtes Cypher d'Exploration**

**Pour explorer votre graphe dans [Neo4j Browser](https://console-preview.neo4j.io/tools/query) :**

```cypher
// ğŸ“Š Vue d'ensemble du graphe complet
MATCH (d:Document)-[r]-(c:Chunk)
RETURN d, r, c
LIMIT 50;

// ğŸ“ˆ Statistiques gÃ©nÃ©rales du Knowledge Graph
MATCH (d:Document) 
WITH count(d) as documents
MATCH (c:Chunk) 
WITH documents, count(c) as chunks
MATCH ()-[r]->() 
RETURN documents, chunks, count(r) as total_relations;

// ğŸ”— Relations par type avec comptage
MATCH ()-[r]->() 
RETURN type(r) as relation_type, count(r) as count 
ORDER BY count DESC;

// ğŸ“„ Documents avec leurs chunks et mÃ©tadonnÃ©es
MATCH (d:Document)-[:CONTAINS_CHUNK]->(c:Chunk)
RETURN d.filename, d.chunk_count, d.created_at, 
       count(c) as actual_chunks, 
       collect(c.chunkIndex)[0..3] as first_chunks
ORDER BY d.created_at DESC;

// ğŸ•¸ï¸ Navigation sÃ©quentielle dans un document
MATCH (d:Document {filename: 'your-document.pdf'})-[:CONTAINS_CHUNK]->(c:Chunk)
OPTIONAL MATCH (c)-[:NEXT_CHUNK]->(next:Chunk)
OPTIONAL MATCH (c)-[:PREVIOUS_CHUNK]->(prev:Chunk)
RETURN c.chunkIndex, c.text[0..100] + '...' as preview,
       prev.chunkIndex as previous, next.chunkIndex as next
ORDER BY c.chunkIndex;

// ğŸŒ Relations sÃ©mantiques inter-documents
MATCH (c1:Chunk)-[r:RELATES_TO]->(c2:Chunk)
WHERE c1.filename <> c2.filename
RETURN c1.filename, c2.filename, r.similarity,
       c1.text[0..80] + '...' as chunk1_preview,
       c2.text[0..80] + '...' as chunk2_preview
ORDER BY r.similarity DESC
LIMIT 20;

// ğŸ” Recherche textuelle simple
MATCH (c:Chunk)
WHERE toLower(c.text) CONTAINS toLower('votre_terme_recherche')
RETURN c.filename, c.chunkIndex, c.text[0..150] + '...' as preview
LIMIT 10;

// ğŸ“Š Chunks les plus connectÃ©s (hubs sÃ©mantiques)
MATCH (c:Chunk)-[r:RELATES_TO]-()
WITH c, count(r) as connections
WHERE connections > 2
RETURN c.filename, c.chunkIndex, connections,
       c.text[0..100] + '...' as preview
ORDER BY connections DESC
LIMIT 10;

// ğŸ¯ Analyse de qualitÃ© des embeddings
MATCH (c:Chunk)
WHERE c.textEmbedding IS NULL
RETURN count(c) as chunks_without_embeddings;

// ğŸ”„ Chemins entre deux documents spÃ©cifiques  
MATCH path = shortestPath(
  (d1:Document {filename: 'doc1.pdf'})-[*]-(d2:Document {filename: 'doc2.pdf'})
)
RETURN path, length(path) as path_length;

// ğŸ“‹ MÃ©tadonnÃ©es complÃ¨tes d'un chunk spÃ©cifique
MATCH (c:Chunk {filename: 'your-doc.pdf', chunkIndex: 0})
OPTIONAL MATCH (c)-[r1:RELATES_TO]->(related:Chunk)
OPTIONAL MATCH (c)-[r2:NEXT_CHUNK]->(next:Chunk)
OPTIONAL MATCH (c)-[r3:PREVIOUS_CHUNK]->(prev:Chunk)
RETURN c, 
       collect(DISTINCT related.filename) as related_docs,
       next.chunkIndex as next_chunk,
       prev.chunkIndex as prev_chunk;
```

### **ğŸ¯ RequÃªtes Cypher AvancÃ©es**

```cypher
// ğŸ§  Simulation de recherche vectorielle manuelle
MATCH (c:Chunk)
WITH c, gds.similarity.cosine(
    c.textEmbedding, 
    [/* insÃ©rer votre vecteur de 1536 dimensions ici */]
) AS similarity
WHERE similarity > 0.8
RETURN c.filename, c.text[0..150] + '...' as preview, similarity
ORDER BY similarity DESC
LIMIT 5;

// ğŸŒ Analyse de clustering sÃ©mantique
CALL gds.louvain.stream({
  nodeProjection: 'Chunk',
  relationshipProjection: {
    RELATES_TO: {
      type: 'RELATES_TO',
      orientation: 'UNDIRECTED',
      properties: 'similarity'
    }
  }
}) YIELD nodeId, communityId
WITH gds.util.asNode(nodeId) AS chunk, communityId
RETURN communityId, 
       collect(DISTINCT chunk.filename) as documents,
       count(chunk) as chunks_in_cluster,
       collect(chunk.text[0..50])[0..3] as sample_texts
ORDER BY chunks_in_cluster DESC;

// ï¿½ Analyse de densitÃ© du graphe par document
MATCH (d:Document)-[:CONTAINS_CHUNK]->(c:Chunk)
OPTIONAL MATCH (c)-[r:RELATES_TO]-()
WITH d, count(DISTINCT c) as chunks, count(r) as relations
RETURN d.filename, chunks, relations, 
       CASE WHEN chunks > 1 
            THEN round((relations * 1.0) / (chunks * (chunks-1)) * 100, 2) 
            ELSE 0 END as density_percentage
ORDER BY density_percentage DESC;

// ğŸ”— DÃ©tection de chunks "pont" entre documents
MATCH (c:Chunk)-[:RELATES_TO]-(other:Chunk)
WHERE c.filename <> other.filename
WITH c, collect(DISTINCT other.filename) as connected_docs
WHERE size(connected_docs) > 2
RETURN c.filename, c.chunkIndex, connected_docs,
       c.text[0..100] + '...' as bridge_content
ORDER BY size(connected_docs) DESC;

// ğŸ“ˆ Ã‰volution temporelle de l'ingestion
MATCH (d:Document)
WITH d.created_at.year as year, d.created_at.month as month, count(d) as docs
RETURN year, month, docs
ORDER BY year, month;

// ğŸ¯ Recherche par proximitÃ© sÃ©mantique (k-NN manuel)
MATCH (target:Chunk {filename: 'your-doc.pdf', chunkIndex: 0})
MATCH (c:Chunk)
WHERE c <> target
WITH c, gds.similarity.cosine(target.textEmbedding, c.textEmbedding) as similarity
ORDER BY similarity DESC
LIMIT 10
RETURN c.filename, c.chunkIndex, similarity,
       c.text[0..120] + '...' as similar_content;
```

**ï¿½ğŸ’¡ Conseils d'utilisation :**
- **Neo4j Browser** : https://console-preview.neo4j.io/tools/query
- Remplacez `'your-document.pdf'` par vos vrais noms de fichiers  
- Ajustez les `LIMIT` selon la taille de votre corpus
- Utilisez `PROFILE` ou `EXPLAIN` pour analyser les performances
- Les rÃ©sultats s'affichent en mode graphique interactif
- **GDS (Graph Data Science)** requis pour les algorithmes avancÃ©s

### **Workflow GraphRAG**

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ Utilisateur
    participant UI as ğŸ¨ Streamlit
    participant API as âš¡ FastAPI
    participant Neo4j as ğŸ—„ï¸ Neo4j
    participant OpenAI as ğŸ¤– OpenAI
    
    %% Phase 1: Ingestion de Document
    Note over User,OpenAI: ğŸ“„ Phase 1: Ingestion de Document
    User->>+UI: Upload Document (PDF/MD/DOCX)
    UI->>+API: POST /ingest_file
    API->>API: Parse & Chunk Document
    API->>+OpenAI: Generate Embeddings
    OpenAI-->>-API: Vector[1536] per chunk
    API->>+Neo4j: Store Chunks + Embeddings
    Neo4j->>Neo4j: Create NEXT/PREV Relations
    Neo4j-->>-API: Ingestion Complete
    API-->>-UI: Success Response
    UI-->>-User: Document Processed âœ…
    
    %% Phase 2: Construction Relations
    Note over User,OpenAI: ğŸ•¸ï¸ Phase 2: Construction Relations SÃ©mantiques
    User->>+UI: Build Inter-doc Relations
    UI->>+API: POST /smart_inter_document_relationships
    API->>+Neo4j: Find Similar Chunks (cosine > 0.8)
    Neo4j->>Neo4j: Create RELATES_TO Relations
    Neo4j-->>-API: Relations Created
    API-->>-UI: Graph Enhanced âœ…
    UI-->>-User: Knowledge Graph Ready ğŸ•¸ï¸
    
    %% Phase 3: Recherche Intelligente  
    Note over User,OpenAI: ğŸ” Phase 3: Recherche Contextuelle
    User->>+UI: Ask Question
    UI->>+API: POST /semantic_search_with_context
    API->>+OpenAI: Embed Question
    OpenAI-->>-API: Question Vector[1536]
    API->>+Neo4j: Vector Search + Graph Traversal
    Neo4j->>Neo4j: Find Similar Chunks (threshold > 0.9)
    Neo4j->>Neo4j: Enrich with NEXT/PREV/RELATES_TO
    Neo4j-->>-API: Contextualized Chunks
    API->>+OpenAI: Generate Answer with Context
    OpenAI-->>-API: Intelligent Response
    API-->>-UI: Enhanced Results
    UI-->>-User: Answer + Sources + Context ğŸ§ 
```

**Ã‰tapes DÃ©taillÃ©es :**

1. **ğŸ“„ Ingestion** : Document â†’ Parsing â†’ Chunking â†’ Embeddings â†’ Neo4j Storage
2. **ğŸ•¸ï¸ Relations** : Analyse similaritÃ© â†’ CrÃ©ation liens sÃ©mantiques â†’ Graphe enrichi  
3. **ğŸ” Recherche** : Question â†’ Vector Search â†’ Filtrage seuil â†’ Enrichissement contexte
4. **âœ¨ GÃ©nÃ©ration** : Contexte Ã©tendu â†’ LLM â†’ RÃ©ponse intelligente avec sources

## âš¡ Installation Rapide

### **1. PrÃ©requis**
- Python 3.11+
- Neo4j 5.x avec support vectoriel
- ClÃ© API OpenAI
- Git

### **2. Clone & Setup**
```bash
git clone https://github.com/famibelle/KnowledgeGraphRag.git
cd KnowledgeGraphRag

# CrÃ©er l'environnement virtuel
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### **3. Configuration Environnement**
```bash
# Copier le fichier d'exemple
copy .env.example .env

# Ã‰diter .env avec vos paramÃ¨tres
```

**Contenu `.env` requis :**
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Neo4j Configuration
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password
NEO4J_DATABASE=neo4j
```

### **4. Initialisation Neo4j**
```bash
# DÃ©marrer l'API
cd KnowledgeGraphRagAPI
python -m uvicorn main:app --reload

# Dans un autre terminal : Initialiser la base
curl -X POST "http://localhost:8000/initialize_db"
```

### **5. Lancement Interface**
```bash
# Dans le rÃ©pertoire racine
streamlit run streamlit_rag_simple.py
```

## ğŸ“– Utilisation

### **Interface Web (RecommandÃ©e)**
1. Ouvrir `http://localhost:8501` (Streamlit)
2. **ğŸ“¤ Onglet "Gestion Documents"** : Upload vos fichiers
3. **ğŸ” Onglet "Recherche RAG"** : Poser vos questions
4. **ğŸ•¸ï¸ Onglet "Graphe"** : Explorer les relations

### **API REST**
Documentation interactive : `http://localhost:8000/docs`

**Endpoints principaux :**
- `POST /ingest_file` - Ingestion de documents
- `POST /semantic_search_with_context` - Recherche avec contexte graphique
- `POST /query` - Recherche avec rÃ©ponse LLM
- `GET /graph_stats` - Statistiques du graphe

### **Exemple API**
```bash
# Recherche contextuelle
curl -X POST "http://localhost:8000/semantic_search_with_context" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "rÃ©sultats financiers LuxConnect",
    "top_k": 5,
    "similarity_threshold": 0.9
  }'
```

## ğŸ§© Architecture DÃ©taillÃ©e

### **1. Recherche SÃ©mantique Hybride**
Notre approche unique combine :
- **Recherche vectorielle** : SimilaritÃ© cosinus sur embeddings 1536D
- **Filtrage par seuil** : Ã‰limination automatique des rÃ©sultats non pertinents
- **Enrichissement contextuel** : Navigation dans les relations du graphe
- **MÃ©tadonnÃ©es dynamiques** : Informations sur les documents sources

### **2. Parallel Processing OptimisÃ©**
```python
# Exemple d'implÃ©mentation
with ThreadPoolExecutor() as executor:
    result = await loop.run_in_executor(
        executor,
        kg.query,  # RequÃªte Neo4j
        cypher_query,
        parameters
    )
```

**Avantages :**
- âš¡ **22+ opÃ©rations parallÃ©lisÃ©es** dans le code
- ğŸš€ **Performance sub-seconde** pour la plupart des requÃªtes
- ğŸ”„ **Traitement asynchrone** des embeddings et requÃªtes

### **3. Gestion Intelligente des Relations**
```cypher
-- CrÃ©ation automatique de relations sÃ©mantiques
MATCH (c1:Chunk), (c2:Chunk)
WHERE c1.filename <> c2.filename 
  AND gds.similarity.cosine(c1.textEmbedding, c2.textEmbedding) > 0.85
CREATE (c1)-[:RELATES_TO {score: similarity}]->(c2)
```

### **4. StratÃ©gies de Filtrage AvancÃ©es**
- **Seuil dynamique** : Adaptation selon le contexte
- **Filtrage multi-niveaux** : Score + pertinence sÃ©mantique
- **PrÃ©vention des hallucinations** : Pas de rÃ©ponse sans contexte valide

## ğŸ”§ Configuration AvancÃ©e

### **ParamÃ¨tres de Performance**
```python
# Dans main.py - Ajustement des seuils
similarity_threshold: float = Field(
    default=0.9,
    ge=0.1, le=1.0,
    description="Seuil de similaritÃ© (0.9=trÃ¨s pertinent, 0.7=recherche large)"
)
```

### **Optimisation Neo4j**
```cypher
-- Index vectoriel (crÃ©Ã© automatiquement)
CREATE VECTOR INDEX GrahRAG FOR (c:Chunk) ON (c.textEmbedding)
OPTIONS {indexConfig: {
  `vector.dimensions`: 1536,
  `vector.similarity_function`: 'cosine'
}}
```

## ğŸ§ª Tests et Validation

### **Tests de Robustesse**
```bash
python test_api_robustness.py  # Tests automatisÃ©s API
python test_parallel_efficiency.py  # Performance parallÃ¨le
```

### **Exemples de RequÃªtes**
- **Mono-document** : "Quels sont les rÃ©sultats financiers de LuxConnect?"
- **Multi-documents** : "LuxConnect financials et TMD utilisation IA friction"
- **Contextuelle** : "Comment l'innovation technologique impacte les performances?"

## ğŸ“Š MÃ©triques de Performance

### **Benchmarks Typiques**
- **Recherche vectorielle** : < 100ms sur 10K+ chunks
- **GÃ©nÃ©ration LLM** : 2-5 secondes selon la complexitÃ©
- **Ingestion document** : 30-60 secondes selon la taille
- **Relations inter-documents** : 1-3 minutes selon le corpus

### **CapacitÃ©s ScalabilitÃ©**
- âœ… **Millions de chunks** supportÃ©s (index vectoriel Neo4j)
- âœ… **Centaines de documents** simultanÃ©s
- âœ… **RequÃªtes parallÃ¨les** sans dÃ©gradation

### **ğŸ”§ Maintenance et Surveillance Neo4j**

**RequÃªtes de maintenance Ã  exÃ©cuter rÃ©guliÃ¨rement :**

```cypher
// ğŸ“ˆ SantÃ© gÃ©nÃ©rale du graphe
CALL db.stats.retrieve('GRAPH COUNTS') YIELD data
RETURN data;

// ğŸ—‚ï¸ Informations sur les index vectoriels
SHOW INDEXES 
WHERE type = 'VECTOR'
YIELD name, state, populationPercent, type;

// ğŸ“Š Analyse de l'utilisation mÃ©moire
CALL dbms.queryJmx('java.lang:type=Memory') 
YIELD attributes 
RETURN attributes.HeapMemoryUsage, attributes.NonHeapMemoryUsage;

// ğŸ” Performance des requÃªtes lentes
CALL db.stats.retrieve('QUERIES') YIELD data
UNWIND data.queries as query
WHERE query.elapsedTimeMillis > 1000
RETURN query.query, query.elapsedTimeMillis, query.executionCount
ORDER BY query.elapsedTimeMillis DESC
LIMIT 10;

// ğŸ§¹ Nettoyage : Supprimer chunks sans embeddings
MATCH (c:Chunk)
WHERE c.textEmbedding IS NULL
DELETE c;

// ğŸ”„ Re-crÃ©ation de l'index vectoriel (si nÃ©cessaire)
DROP INDEX GrahRAG IF EXISTS;
CREATE VECTOR INDEX GrahRAG FOR (c:Chunk) ON (c.textEmbedding)
OPTIONS {indexConfig: {
  `vector.dimensions`: 1536,
  `vector.similarity_function`: 'cosine'
}};

// ğŸ“‹ Backup des mÃ©tadonnÃ©es importantes
MATCH (d:Document)
RETURN d.filename, d.created_at, d.chunk_count, d.file_extension
ORDER BY d.created_at DESC;
```

## ğŸ¤ Contribution

### **Structure du Projet**
```
â”œâ”€â”€ KnowledgeGraphRagAPI/     # Backend FastAPI
â”‚   â”œâ”€â”€ main.py              # API principale
â”‚   â””â”€â”€ requirements.txt     # DÃ©pendances backend
â”œâ”€â”€ streamlit_rag_simple.py  # Interface Streamlit
â”œâ”€â”€ requirements.txt         # DÃ©pendances globales
â”œâ”€â”€ .env.example            # Template configuration
â””â”€â”€ README.md               # Cette documentation
```

### **DÃ©veloppement Local**
1. Fork le repository
2. CrÃ©er une branche feature : `git checkout -b feature/amazing-feature`
3. Tester localement avec Neo4j + OpenAI
4. Commit : `git commit -m 'Add amazing feature'`
5. Push : `git push origin feature/amazing-feature`
6. Ouvrir une Pull Request

## ğŸ› DÃ©pannage

### **ProblÃ¨mes Courants**
- **Neo4j connexion** : VÃ©rifier `.env` et URL/credentials
- **OpenAI API** : Valider la clÃ© API et quotas
- **Import errors** : `pip install -r requirements.txt`
- **Performance lente** : VÃ©rifier l'index vectoriel Neo4j

### **Logs et Debug**
```bash
# Activer les logs dÃ©taillÃ©s
export LOG_LEVEL=DEBUG
python -m uvicorn main:app --log-level debug
```

## ğŸ“ License

MIT License - Voir [LICENSE](LICENSE) pour les dÃ©tails.

## ğŸ™ Remerciements

- **Neo4j** pour la technologie graphe + vectorielle
- **OpenAI** pour les embeddings et LLM
- **FastAPI** & **Streamlit** pour les frameworks
- **LangChain** pour l'intÃ©gration Ã©lÃ©gante

---

**ğŸš€ PrÃªt Ã  explorer vos documents avec l'IA ? Commencez dÃ¨s maintenant !**

*Pour plus d'aide : [Issues GitHub](https://github.com/famibelle/KnowledgeGraphRag/issues)*

# ğŸ§  GraphRAG Knowledge Graph System

> **SystÃ¨me intelligent de questions-rÃ©ponses basÃ© sur un graphe de connaissances**
> 
> Combine Neo4j, OpenAI et FastAPI pour crÃ©er un systÃ¨me RAG (Retrieval Augmented Generation) avancÃ© avec recherche sÃ©mantique vectorielle et navigation contextuelle dans un graphe de connaissances.

[![Python](https://img.shields.io/badge/Python-3.11+-blue.svg)](https://python.org)
[![Neo4j](https://img.shields.io/badge/Neo4j-5.x-green.svg)](https://neo4j.com)
[![FastAPI](https://img.shields.io/badge/FastAPI-Latest-red.svg)](https://fastapi.tiangolo.com)
[![Streamlit](https://img.shields.io/badge/Streamlit-Latest-orange.svg)](https://streamlit.io)

## ğŸš€ FonctionnalitÃ©s ClÃ©s

### ğŸ” **Recherche SÃ©mantique AvancÃ©e**
- **Embeddings vectoriels** via OpenAI (text-embedding-3-small, 1536 dimensions)
- **Index vectoriel Neo4j natif** pour une recherche sub-seconde
- **Seuils de similaritÃ© configurables** (0.7-0.9) pour Ã©viter les rÃ©sultats non pertinents
- **Support multilingue** optimisÃ© pour le franÃ§ais

### ğŸ•¸ï¸ **Graphe de Connaissances Intelligent**
- **Relations automatiques** entre chunks similaires (`RELATES_TO`)
- **Navigation sÃ©quentielle** dans les documents (`NEXT_CHUNK`, `PREVIOUS_CHUNK`)
- **Contexte enrichi** avec mÃ©tadonnÃ©es des documents
- **RequÃªtes Cypher flexibles** pour l'exploration avancÃ©e

### ğŸ“š **Ingestion Multi-Format**
- **Formats supportÃ©s** : PDF, Markdown, Word, Texte
- **DÃ©coupage intelligent** en chunks optimisÃ©s
- **CrÃ©ation automatique** du graphe de connaissances
- **Processing parallÃ¨le** pour les performances

### ğŸ§  **GÃ©nÃ©ration LLM Contextuelle**
- **Integration ChatGPT-3.5-turbo** pour les rÃ©ponses
- **RÃ©ponses contextualisÃ©es** basÃ©es sur les documents
- **Filtrage intelligent** pour Ã©viter les hallucinations
- **Recherche multi-documents** pour des requÃªtes complexes

## ğŸ³ DÃ©ploiement Docker (RecommandÃ©)

### **DÃ©marrage Ultra-Rapide**

```bash
# 1. TÃ©lÃ©charger la configuration
curl -o .env.docker https://raw.githubusercontent.com/famibelle/KnowledgeGraphRag/master/.env.docker

# 2. Ã‰diter avec vos clÃ©s API
nano .env.docker  # ou notepad .env.docker sur Windows

# 3. DÃ©marrer avec l'image publiÃ©e
docker run -d \
  --name graphrag-demo \
  -p 8000:8000 \
  -p 8501:8501 \
  --env-file .env.docker \
  famibelle/graphrag-knowledge-graph:latest
```

**ğŸ‰ C'est tout ! Ouvrez http://localhost:8501**

### **Images Docker Disponibles**

| Registry | Image | Commande |
|----------|--------|----------|
| ğŸ³ **Docker Hub** | `famibelle/graphrag-knowledge-graph` | `docker pull famibelle/graphrag-knowledge-graph:latest` |
| ğŸ“¦ **GitHub** | `ghcr.io/famibelle/knowledgegraphrag` | `docker pull ghcr.io/famibelle/knowledgegraphrag:latest` |

### **Options de DÃ©ploiement**

#### **Option 1: Docker Run (Simple)**
```bash
docker run -d -p 8000:8000 -p 8501:8501 --env-file .env.docker famibelle/graphrag-knowledge-graph:latest
```

#### **Option 2: Docker Compose (RecommandÃ©)**
```bash
# Avec image publiÃ©e
curl -o docker-compose.production.yml https://raw.githubusercontent.com/famibelle/KnowledgeGraphRag/master/docker-compose.production.yml
docker-compose -f docker-compose.production.yml up -d
```

#### **Option 3: Build Local**
```bash
git clone https://github.com/famibelle/KnowledgeGraphRag.git
cd KnowledgeGraphRag
make run
```

## ğŸ—ï¸ Architecture Technique

### **Stack Technologique**

```mermaid
flowchart TB
    %% User Interface Layer
    subgraph "ğŸ¨ Interface Utilisateur"
        UI[Streamlit Frontend<br/>Port 8501]
        BROWSER[ğŸŒ Navigateur Web]
    end
    
    %% API Layer
    subgraph "âš¡ API Layer"
        API[FastAPI Backend<br/>Port 8000<br/>ThreadPoolExecutor]
        DOCS[ğŸ“Š Swagger/ReDoc<br/>Auto-generated]
    end
    
    %% External Services
    subgraph "ğŸ¤– Services IA"
        OPENAI_EMB[OpenAI Embeddings<br/>text-embedding-3-small<br/>1536 dimensions]
        OPENAI_LLM[OpenAI LLM<br/>GPT-3.5-turbo<br/>Response Generation]
    end
    
    %% Database Layer
    subgraph "ğŸ—„ï¸ Base de DonnÃ©es"
        NEO4J[Neo4j 5.x<br/>Graph + Vector DB]
        VECTOR_IDX[Vector Index<br/>GrahRAG<br/>Cosine Similarity]
        GRAPH_REL[Graph Relations<br/>NEXT/PREV/RELATES_TO]
    end
    
    %% Data Processing
    subgraph "ğŸ“Š Traitement Documents"
        INGEST[Document Ingestion<br/>PDF/MD/DOCX/TXT]
        CHUNK[Text Chunking<br/>RecursiveCharacterTextSplitter]
        EMBED[Embedding Generation<br/>Parallel Processing]
    end
    
    %% Connections
    BROWSER --> UI
    UI <--> API
    API --> DOCS
    
    API <--> OPENAI_EMB
    API <--> OPENAI_LLM
    API <--> NEO4J
    
    NEO4J --> VECTOR_IDX
    NEO4J --> GRAPH_REL
    
    API --> INGEST
    INGEST --> CHUNK
    CHUNK --> EMBED
    EMBED --> NEO4J
    
    %% Styling
    classDef frontend fill:#e8f5e8,stroke:#2e7d32,stroke-width:2px
    classDef backend fill:#e3f2fd,stroke:#1565c0,stroke-width:2px
    classDef ai fill:#fff3e0,stroke:#ef6c00,stroke-width:2px
    classDef database fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    classDef processing fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    class UI,BROWSER frontend
    class API,DOCS backend
    class OPENAI_EMB,OPENAI_LLM ai
    class NEO4J,VECTOR_IDX,GRAPH_REL database
    class INGEST,CHUNK,EMBED processing
```

**Architecture Technique :**
- **Frontend** : Streamlit (Python) - Interface web interactive
- **Backend** : FastAPI (Python async) - API REST haute performance
- **IA Services** : OpenAI (embeddings + LLM) - Traitement sÃ©mantique
- **Base de DonnÃ©es** : Neo4j 5.x - Graphe + index vectoriel natif
- **Performance** : ThreadPoolExecutor - Traitement parallÃ¨le optimisÃ©

### **ModÃ¨le de DonnÃ©es Neo4j**

```mermaid
graph LR
    %% EntitÃ©s principales
    D1[ğŸ“„ Document A]
    D2[ğŸ“„ Document B]
    
    C1[ğŸ“ Chunk 1]
    C2[ğŸ“ Chunk 2]
    C3[ğŸ“ Chunk 3]
    C4[ğŸ“ Chunk 4]
    
    %% Relations document â†’ chunks
    D1 --> C1
    D1 --> C2
    D2 --> C3
    D2 --> C4
    
    %% Navigation sÃ©quentielle
    C1 -.-> C2
    
    %% Relations sÃ©mantiques inter-documents
    C1 -.-> C3
    C2 -.-> C4
    
    %% Styling
    classDef doc fill:#e1f5fe,stroke:#1976d2,stroke-width:2px
    classDef chunk fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    
    class D1,D2 doc
    class C1,C2,C3,C4 chunk
```

**Structure GraphRAG :**
```cypher
(:Document) -[CONTAINS_CHUNK]-> (:Chunk)
(:Chunk) -[NEXT_CHUNK]-> (:Chunk)  
(:Chunk) -[RELATES_TO]-> (:Chunk)
```

**Types de Relations :**
- **Ligne pleine** : CONTAINS_CHUNK (hiÃ©rarchique)
- **Ligne pointillÃ©e** : NEXT_CHUNK (sÃ©quentielle) 
- **Ligne pointillÃ©e courbe** : RELATES_TO (sÃ©mantique inter-documents)

### **ğŸ” RequÃªtes Cypher d'Exploration**

**Pour explorer votre graphe dans [Neo4j Browser](https://console-preview.neo4j.io/tools/query) :**

```cypher
// ğŸ“Š Vue d'ensemble du graphe complet
MATCH (d:Document)-[r]-(c:Chunk)
RETURN d, r, c
LIMIT 50;

// ğŸ“ˆ Statistiques gÃ©nÃ©rales du Knowledge Graph
MATCH (d:Document) 
WITH count(d) as documents
MATCH (c:Chunk) 
WITH documents, count(c) as chunks
MATCH ()-[r]->() 
RETURN documents, chunks, count(r) as total_relations;

// ğŸ“„ Documents avec leurs chunks et mÃ©tadonnÃ©es
MATCH (d:Document)-[:CONTAINS_CHUNK]->(c:Chunk)
RETURN d.filename, d.chunk_count, d.created_at, 
       count(c) as actual_chunks, 
       collect(c.chunkIndex)[0..3] as first_chunks
ORDER BY d.created_at DESC;

// ğŸ•¸ï¸ Navigation sÃ©quentielle dans un document
MATCH (d:Document {filename: 'your-document.pdf'})-[:CONTAINS_CHUNK]->(c:Chunk)
OPTIONAL MATCH (c)-[:NEXT_CHUNK]->(next:Chunk)
OPTIONAL MATCH (c)-[:PREVIOUS_CHUNK]->(prev:Chunk)
RETURN c.chunkIndex, c.text[0..100] + '...' as preview,
       prev.chunkIndex as previous, next.chunkIndex as next
ORDER BY c.chunkIndex;

// ğŸŒ Relations sÃ©mantiques inter-documents
MATCH (c1:Chunk)-[r:RELATES_TO]->(c2:Chunk)
WHERE c1.filename <> c2.filename
RETURN c1.filename, c2.filename, r.similarity,
       c1.text[0..80] + '...' as chunk1_preview,
       c2.text[0..80] + '...' as chunk2_preview
ORDER BY r.similarity DESC
LIMIT 20;

// ğŸ“Š Chunks les plus connectÃ©s (hubs sÃ©mantiques)
MATCH (c:Chunk)-[r:RELATES_TO]-()
WITH c, count(r) as connections
WHERE connections > 2
RETURN c.filename, c.chunkIndex, connections,
       c.text[0..100] + '...' as preview
ORDER BY connections DESC
LIMIT 10;

// ğŸ”„ Chemins entre deux documents spÃ©cifiques  
MATCH path = shortestPath(
  (d1:Document {filename: 'doc1.pdf'})-[*]-(d2:Document {filename: 'doc2.pdf'})
)
RETURN path, length(path) as path_length;

// ğŸ“‹ MÃ©tadonnÃ©es complÃ¨tes d'un chunk spÃ©cifique
MATCH (c:Chunk {filename: 'your-doc.pdf', chunkIndex: 0})
OPTIONAL MATCH (c)-[r1:RELATES_TO]->(related:Chunk)
OPTIONAL MATCH (c)-[r2:NEXT_CHUNK]->(next:Chunk)
OPTIONAL MATCH (c)-[r3:PREVIOUS_CHUNK]->(prev:Chunk)
RETURN c, 
       collect(DISTINCT related.filename) as related_docs,
       next.chunkIndex as next_chunk,
       prev.chunkIndex as prev_chunk;
```

### **ğŸ¯ RequÃªtes Cypher AvancÃ©es**

```cypher

// ğŸ”— DÃ©tection de chunks "pont" entre documents
MATCH (c:Chunk)-[:RELATES_TO]-(other:Chunk)
WHERE c.filename <> other.filename
WITH c, collect(DISTINCT other.filename) as connected_docs
WHERE size(connected_docs) > 2
RETURN c.filename, c.chunkIndex, connected_docs,
       c.text[0..100] + '...' as bridge_content
ORDER BY size(connected_docs) DESC;

// ğŸ¯ Recherche par proximitÃ© sÃ©mantique (k-NN manuel)
MATCH (target:Chunk {filename: 'your-doc.pdf', chunkIndex: 0})
MATCH (c:Chunk)
WHERE c <> target
WITH c, gds.similarity.cosine(target.textEmbedding, c.textEmbedding) as similarity
ORDER BY similarity DESC
LIMIT 10
RETURN c.filename, c.chunkIndex, similarity,
       c.text[0..120] + '...' as similar_content;
```

**ï¿½ğŸ’¡ Conseils d'utilisation :**
- **Neo4j Browser** : https://console-preview.neo4j.io/tools/query
- Remplacez `'your-document.pdf'` par vos vrais noms de fichiers  
- Ajustez les `LIMIT` selon la taille de votre corpus
- Utilisez `PROFILE` ou `EXPLAIN` pour analyser les performances
- Les rÃ©sultats s'affichent en mode graphique interactif
- **GDS (Graph Data Science)** requis pour les algorithmes avancÃ©s

### **Workflow GraphRAG**

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ Utilisateur
    participant UI as ğŸ¨ Streamlit
    participant API as âš¡ FastAPI
    participant Neo4j as ğŸ—„ï¸ Neo4j
    participant OpenAI as ğŸ¤– OpenAI
    
    %% Phase 1: Ingestion de Document
    Note over User,OpenAI: ğŸ“„ Phase 1: Ingestion de Document
    User->>+UI: Upload Document (PDF/MD/DOCX)
    UI->>+API: POST /ingest_file
    API->>API: Parse & Chunk Document
    API->>+OpenAI: Generate Embeddings
    OpenAI-->>-API: Vector[1536] per chunk
    API->>+Neo4j: Store Chunks + Embeddings
    Neo4j->>Neo4j: Create NEXT/PREV Relations
    Neo4j-->>-API: Ingestion Complete
    API-->>-UI: Success Response
    UI-->>-User: Document Processed âœ…
    
    %% Phase 2: Construction Relations
    Note over User,OpenAI: ğŸ•¸ï¸ Phase 2: Construction Relations SÃ©mantiques
    User->>+UI: Build Inter-doc Relations
    UI->>+API: POST /smart_inter_document_relationships
    API->>+Neo4j: Find Similar Chunks (cosine > 0.8)
    Neo4j->>Neo4j: Create RELATES_TO Relations
    Neo4j-->>-API: Relations Created
    API-->>-UI: Graph Enhanced âœ…
    UI-->>-User: Knowledge Graph Ready ğŸ•¸ï¸
    
    %% Phase 3: Recherche Intelligente  
    Note over User,OpenAI: ğŸ” Phase 3: Recherche Contextuelle
    User->>+UI: Ask Question
    UI->>+API: POST /semantic_search_with_context
    API->>+OpenAI: Embed Question
    OpenAI-->>-API: Question Vector[1536]
    API->>+Neo4j: Vector Search + Graph Traversal
    Neo4j->>Neo4j: Find Similar Chunks (threshold > 0.9)
    Neo4j->>Neo4j: Enrich with NEXT/PREV/RELATES_TO
    Neo4j-->>-API: Contextualized Chunks
    API->>+OpenAI: Generate Answer with Context
    OpenAI-->>-API: Intelligent Response
    API-->>-UI: Enhanced Results
    UI-->>-User: Answer + Sources + Context ğŸ§ 
```

**Ã‰tapes DÃ©taillÃ©es :**

1. **ğŸ“„ Ingestion** : Document â†’ Parsing â†’ Chunking â†’ Embeddings â†’ Neo4j Storage
2. **ğŸ•¸ï¸ Relations** : Analyse similaritÃ© â†’ CrÃ©ation liens sÃ©mantiques â†’ Graphe enrichi  
3. **ğŸ” Recherche** : Question â†’ Vector Search â†’ Filtrage seuil â†’ Enrichissement contexte
4. **âœ¨ GÃ©nÃ©ration** : Contexte Ã©tendu â†’ LLM â†’ RÃ©ponse intelligente avec sources

## âš¡ Installation Rapide

### **1. PrÃ©requis**
- Python 3.11+
- Neo4j 5.x avec support vectoriel
- ClÃ© API OpenAI
- Git

### **2. Clone & Setup**
```bash
git clone https://github.com/famibelle/KnowledgeGraphRag.git
cd KnowledgeGraphRag

# CrÃ©er l'environnement virtuel
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### **3. Configuration Environnement**
```bash
# Copier le fichier d'exemple
copy .env.example .env

# Ã‰diter .env avec vos paramÃ¨tres
```

**Contenu `.env` requis :**
```env
# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here

# Neo4j Configuration
NEO4J_URI=neo4j+s://your-instance.databases.neo4j.io
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_neo4j_password
NEO4J_DATABASE=neo4j
```

### **4. Initialisation Neo4j**
```bash
# DÃ©marrer l'API
cd KnowledgeGraphRagAPI
python -m uvicorn main:app --reload

# Dans un autre terminal : Initialiser la base
curl -X POST "http://localhost:8000/initialize_db"
```

### **5. Lancement Interface**
```bash
# Dans le rÃ©pertoire racine
streamlit run streamlit_rag_simple.py
```

## ğŸ“– Utilisation

### **Interface Web (RecommandÃ©e)**
1. Ouvrir `http://localhost:8501` (Streamlit)
2. **ğŸ“¤ Onglet "Gestion Documents"** : Upload vos fichiers
3. **ğŸ” Onglet "Recherche RAG"** : Poser vos questions
4. **ğŸ•¸ï¸ Onglet "Graphe"** : Explorer les relations

### **API REST**
Documentation interactive : `http://localhost:8000/docs`

**Endpoints principaux :**
- `POST /ingest_file` - Ingestion de documents
- `POST /semantic_search_with_context` - Recherche avec contexte graphique
- `POST /query` - Recherche avec rÃ©ponse LLM
- `GET /graph_stats` - Statistiques du graphe

### **Exemple API**
```bash
# Recherche contextuelle
curl -X POST "http://localhost:8000/semantic_search_with_context" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "rÃ©sultats financiers LuxConnect",
    "top_k": 5,
    "similarity_threshold": 0.9
  }'
```

## ğŸ§© Architecture DÃ©taillÃ©e

### **1. Recherche SÃ©mantique Hybride**
Notre approche unique combine :
- **Recherche vectorielle** : SimilaritÃ© cosinus sur embeddings 1536D
- **Filtrage par seuil** : Ã‰limination automatique des rÃ©sultats non pertinents
- **Enrichissement contextuel** : Navigation dans les relations du graphe
- **MÃ©tadonnÃ©es dynamiques** : Informations sur les documents sources

### **2. Parallel Processing OptimisÃ©**
```python
# Exemple d'implÃ©mentation
with ThreadPoolExecutor() as executor:
    result = await loop.run_in_executor(
        executor,
        kg.query,  # RequÃªte Neo4j
        cypher_query,
        parameters
    )
```

**Avantages :**
- âš¡ **22+ opÃ©rations parallÃ©lisÃ©es** dans le code
- ğŸš€ **Performance sub-seconde** pour la plupart des requÃªtes
- ğŸ”„ **Traitement asynchrone** des embeddings et requÃªtes

### **3. Gestion Intelligente des Relations**
```cypher
-- CrÃ©ation automatique de relations sÃ©mantiques
MATCH (c1:Chunk), (c2:Chunk)
WHERE c1.filename <> c2.filename 
  AND gds.similarity.cosine(c1.textEmbedding, c2.textEmbedding) > 0.85
CREATE (c1)-[:RELATES_TO {score: similarity}]->(c2)
```

### **4. StratÃ©gies de Filtrage AvancÃ©es**
- **Seuil dynamique** : Adaptation selon le contexte
- **Filtrage multi-niveaux** : Score + pertinence sÃ©mantique
- **PrÃ©vention des hallucinations** : Pas de rÃ©ponse sans contexte valide


```

## ğŸ§ª Tests et Validation

### **Tests de Robustesse**
```bash
python test_api_robustness.py  # Tests automatisÃ©s API
python test_parallel_efficiency.py  # Performance parallÃ¨le
```

### **Exemples de RequÃªtes**
- **Mono-document** : "Quels sont les rÃ©sultats financiers de LuxConnect?"
- **Multi-documents** : "LuxConnect financials et TMD utilisation IA friction"
- **Contextuelle** : "Comment l'innovation technologique impacte les performances?"

## ğŸ“Š MÃ©triques de Performance

### **Benchmarks Typiques**
- **Recherche vectorielle** : < 100ms sur 10K+ chunks
- **GÃ©nÃ©ration LLM** : 2-5 secondes selon la complexitÃ©
- **Ingestion document** : 30-60 secondes selon la taille
- **Relations inter-documents** : 1-3 minutes selon le corpus

### **CapacitÃ©s ScalabilitÃ©**
- âœ… **Millions de chunks** supportÃ©s (index vectoriel Neo4j)
- âœ… **Centaines de documents** simultanÃ©s
- âœ… **RequÃªtes parallÃ¨les** sans dÃ©gradation

## ğŸ¤ Contribution

### **Structure du Projet**
```
â”œâ”€â”€ KnowledgeGraphRagAPI/     # Backend FastAPI
â”‚   â”œâ”€â”€ main.py              # API principale
â”‚   â””â”€â”€ requirements.txt     # DÃ©pendances backend
â”œâ”€â”€ streamlit_rag_simple.py  # Interface Streamlit
â”œâ”€â”€ requirements.txt         # DÃ©pendances globales
â”œâ”€â”€ .env.example            # Template configuration
â””â”€â”€ README.md               # Cette documentation
```

### **DÃ©veloppement Local**
1. Fork le repository
2. CrÃ©er une branche feature : `git checkout -b feature/amazing-feature`
3. Tester localement avec Neo4j + OpenAI
4. Commit : `git commit -m 'Add amazing feature'`
5. Push : `git push origin feature/amazing-feature`
6. Ouvrir une Pull Request

## ğŸ› DÃ©pannage

### **ProblÃ¨mes Courants**
- **Neo4j connexion** : VÃ©rifier `.env` et URL/credentials
- **OpenAI API** : Valider la clÃ© API et quotas
- **Import errors** : `pip install -r requirements.txt`
- **Performance lente** : VÃ©rifier l'index vectoriel Neo4j

### **Logs et Debug**
```bash
# Activer les logs dÃ©taillÃ©s
export LOG_LEVEL=DEBUG
python -m uvicorn main:app --log-level debug
```

## ğŸ“ License

MIT License - Voir [LICENSE](LICENSE) pour les dÃ©tails.

## ğŸ™ Remerciements

- **Neo4j** pour la technologie graphe + vectorielle
- **OpenAI** pour les embeddings et LLM
- **FastAPI** & **Streamlit** pour les frameworks
- **LangChain** pour l'intÃ©gration Ã©lÃ©gante

---

**ğŸš€ PrÃªt Ã  explorer vos documents avec l'IA ? Commencez dÃ¨s maintenant !**

*Pour plus d'aide : [Issues GitHub](https://github.com/famibelle/KnowledgeGraphRag/issues)*

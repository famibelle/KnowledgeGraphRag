{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d43c9cdc-530d-40df-b9f0-adf02c00c948",
   "metadata": {},
   "source": [
    "# Lesson 5: Adding Relationships to the SEC Knowledge Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f7ac8-5131-4e20-bd93-d727b747bfd8",
   "metadata": {},
   "source": [
    "### Import packages and set up Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "d659e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv \n",
    "# %pip install langchain langchain-community langchain-openai \n",
    "# %pip install neo4j \n",
    "# %pip install textwrap\n",
    "# %pip install pypdf\n",
    "\n",
    "# Installation de yFiles Jupyter Graphs sp√©cialement pour Neo4j\n",
    "# %pip install yfiles_jupyter_graphs_for_neo4j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccc0573",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d235d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import glob\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168766c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import de yFiles pour Neo4j\n",
    "from yfiles_jupyter_graphs_for_neo4j import Neo4jGraphWidget\n",
    "from neo4j import GraphDatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1eab9e-cdbe-4625-8f71-8d13b760e513",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Common data processing\n",
    "import textwrap\n",
    "\n",
    "# Langchain\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "from langchain_community.vectorstores import Neo4jVector\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48baf0cd-e824-4d23-ab52-3c233eee21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from environment\n",
    "load_dotenv('.env', override=True)\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
    "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
    "\n",
    "# Global constants\n",
    "VECTOR_INDEX_NAME = 'Documents_chunks'\n",
    "VECTOR_NODE_LABEL = 'Chunk'\n",
    "VECTOR_SOURCE_PROPERTY = 'text'\n",
    "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c70a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration pour les embeddings OpenAI dans Neo4j\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "OPENAI_BASE_URL = os.getenv('OPENAI_BASE_URL', 'https://api.openai.com/v1')\n",
    "OPENAI_ENDPOINT = OPENAI_BASE_URL + '/embeddings'\n",
    "\n",
    "print(\"üîß Configuration Neo4j et OpenAI\")\n",
    "print(f\"   Neo4j URI: {NEO4J_URI}\")\n",
    "print(f\"   Database: {NEO4J_DATABASE}\")\n",
    "print(f\"   OpenAI Base URL: {OPENAI_BASE_URL}\")\n",
    "print(f\"   OpenAI Endpoint: {OPENAI_ENDPOINT}\")\n",
    "print(f\"   API Key configur√©e: {'‚úÖ' if OPENAI_API_KEY else '‚ùå'}\")\n",
    "\n",
    "# V√©rifier la connexion Neo4j\n",
    "try:\n",
    "    result = kg.query(\"RETURN 1 as test\")\n",
    "    print(\"‚úÖ Connexion Neo4j active\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur connexion Neo4j: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20301e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test de la configuration OPENAI_ENDPOINT\n",
    "def test_openai_endpoint():\n",
    "    \"\"\"Test de la configuration de l'endpoint OpenAI\"\"\"\n",
    "    \n",
    "    print(\"üß™ Test de la configuration OpenAI\")\n",
    "    print(f\"   OPENAI_BASE_URL: {OPENAI_BASE_URL}\")\n",
    "    print(f\"   OPENAI_ENDPOINT: {OPENAI_ENDPOINT}\")\n",
    "    \n",
    "    # V√©rifier que l'endpoint se termine bien par '/embeddings'\n",
    "    if OPENAI_ENDPOINT.endswith('/embeddings'):\n",
    "        print(\"   ‚úÖ Endpoint correctement format√©\")\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è Attention: l'endpoint ne se termine pas par '/embeddings'\")\n",
    "    \n",
    "    # Test simple avec un embedding\n",
    "    try:\n",
    "        from langchain_openai import OpenAIEmbeddings\n",
    "        embeddings = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\",\n",
    "            openai_api_base=OPENAI_BASE_URL\n",
    "        )\n",
    "        test_vector = embeddings.embed_query(\"Test de connexion\")\n",
    "        print(f\"   ‚úÖ Test r√©ussi! Vecteur de dimension: {len(test_vector)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Erreur lors du test: {e}\")\n",
    "        return False\n",
    "\n",
    "# Ex√©cuter le test\n",
    "test_success = test_openai_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8dbc048-131c-422a-aeb7-78014a8e60e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = Neo4jGraph(\n",
    "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ee02a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "pdf_path = \"PDFs\"\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674212f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R√©cup√©rer tous les PDFs\n",
    "pdf_files = glob.glob(f\"{pdf_path}/*.pdf\")\n",
    "print(f\"üìÑ {len(pdf_files)} fichiers PDF trouv√©s\")\n",
    "\n",
    "# Traiter tous les PDFs\n",
    "all_chunks = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    try:\n",
    "        print(f\"Traitement: {os.path.basename(pdf_file)}\")\n",
    "        \n",
    "        # Charger et chunker\n",
    "        loader = PyPDFLoader(pdf_file)\n",
    "        pages = loader.load()\n",
    "        chunks = text_splitter.split_documents(pages)\n",
    "        \n",
    "        # Ajouter m√©tadonn√©es simples\n",
    "        doc_id = str(uuid.uuid4())\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_data = {\n",
    "                'id': str(uuid.uuid4()),\n",
    "                'doc_id': doc_id,\n",
    "                'filename': os.path.basename(pdf_file),\n",
    "                'chunk_index': i,\n",
    "                'text': chunk.page_content,\n",
    "                'word_count': len(chunk.page_content.split())\n",
    "            }\n",
    "            all_chunks.append(chunk_data)\n",
    "        \n",
    "        print(f\"  ‚úÖ {len(chunks)} chunks cr√©√©s\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erreur: {e}\")\n",
    "\n",
    "print(f\"\\nüéØ Total: {len(all_chunks)} chunks pr√™ts\")\n",
    "print(f\"üìä Mots par chunk (moyenne): {sum(c['word_count'] for c in all_chunks) / len(all_chunks):.0f}\")\n",
    "import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778044a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(random.choice(all_chunks), width=100, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27588c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_chunk_node_query = \"\"\"\n",
    "MERGE(mergedChunk:Chunk {id: $chunkParam.id})\n",
    "    ON CREATE SET \n",
    "        mergedChunk.id = $chunkParam.id,\n",
    "        mergedChunk.doc_id = $chunkParam.doc_id, \n",
    "        mergedChunk.filename = $chunkParam.filename, \n",
    "        mergedChunk.chunk_index = $chunkParam.chunk_index, \n",
    "        mergedChunk.text = $chunkParam.text, \n",
    "        mergedChunk.word_count = $chunkParam.word_count \n",
    "RETURN mergedChunk\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07783a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour traiter tous les chunks\n",
    "for chunk in tqdm(all_chunks, desc=\"Cr√©ation des chunks dans Neo4j\"):\n",
    "    print(f\"Creating `:Chunk` node for chunk ID {chunk['id']}\")\n",
    "    result = kg.query(\n",
    "        merge_chunk_node_query, \n",
    "        params={'chunkParam': chunk}\n",
    "    )\n",
    "    \n",
    "print(f\"‚úÖ {len(all_chunks)} chunks cr√©√©s dans Neo4j\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45629c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (n)\n",
    "         RETURN count(n) as nodeCount\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055e0801",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         MATCH (n)\n",
    "         RETURN count(n) as nodeCount\n",
    "         \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d58ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation du vector Index dans Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c50721",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"\"\"\n",
    "         CREATE VECTOR INDEX `GrahRAG` IF NOT EXISTS\n",
    "          FOR (c:Chunk) ON (c.textEmbedding) \n",
    "          OPTIONS { indexConfig: {\n",
    "            `vector.dimensions`: 1536,\n",
    "            `vector.similarity_function`: 'cosine'    \n",
    "         }}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c973770",
   "metadata": {},
   "outputs": [],
   "source": [
    "kg.query(\"SHOW INDEXES\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753f9c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ G√©n√©ration d'embeddings - Strat√©gie simplifi√©e (embeddings pr√©-calcul√©s)\n",
    "def generate_embeddings_simple():\n",
    "    \"\"\"Utilise les embeddings pr√©-calcul√©s (strat√©gie qui fonctionne)\"\"\"\n",
    "    \n",
    "    print(\"üöÄ G√©n√©ration d'embeddings avec la strat√©gie qui fonctionne...\")\n",
    "    print(\"üìã Utilisation des embeddings pr√©-calcul√©s\")\n",
    "    \n",
    "    try:\n",
    "        chunks_updated = 0\n",
    "        for chunk in enriched_chunks:\n",
    "            if 'embedding' in chunk:\n",
    "                kg.query(\"\"\"\n",
    "                    MATCH (c:Chunk {id: $chunk_id})\n",
    "                    CALL db.create.setNodeVectorProperty(c, \"textEmbedding\", $embedding)\n",
    "                    RETURN c.id as updated_id\n",
    "                    \"\"\", \n",
    "                    params={\n",
    "                        \"chunk_id\": chunk['id'],\n",
    "                        \"embedding\": chunk['embedding']\n",
    "                    }\n",
    "                )\n",
    "                chunks_updated += 1\n",
    "                \n",
    "                if chunks_updated % 10 == 0:\n",
    "                    print(f\"   ‚è≥ {chunks_updated} chunks trait√©s...\")\n",
    "        \n",
    "        print(f\"‚úÖ Succ√®s! {chunks_updated} chunks trait√©s avec embeddings pr√©-calcul√©s\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur: {str(e)[:200]}...\")\n",
    "        return False\n",
    "\n",
    "# Ex√©cuter la g√©n√©ration simplifi√©e\n",
    "success = generate_embeddings_simple()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7509a7",
   "metadata": {},
   "source": [
    "## üîç Recherche Vectorielle dans le Knowledge Graph\n",
    "\n",
    "Maintenant que notre Knowledge Graph est op√©rationnel avec des embeddings, nous pouvons effectuer des recherches s√©mantiques avanc√©es !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c7bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß FONCTION DE RECHERCHE VECTORIELLE CORRIG√âE\n",
    "def neo4j_vector_search_robust(question, top_k=5):\n",
    "    \"\"\"Recherche vectorielle avec le bon nom d'index\"\"\"\n",
    "    \n",
    "    print(f\"üîç Recherche pour: '{question}'\")\n",
    "    \n",
    "    try:\n",
    "        from langchain_openai import OpenAIEmbeddings\n",
    "        embeddings_service = OpenAIEmbeddings(\n",
    "            model=\"text-embedding-3-small\"\n",
    "        )\n",
    "        \n",
    "        # G√©n√©rer l'embedding de la question\n",
    "        question_embedding = embeddings_service.embed_query(question)\n",
    "        \n",
    "        # Recherche avec l'embedding g√©n√©r√© et le BON nom d'index\n",
    "        search_query = \"\"\"\n",
    "            CALL db.index.vector.queryNodes('GrahRAG', $top_k, $question_embedding) \n",
    "            YIELD node, score\n",
    "            RETURN score, node.text AS text, node.filename AS source, node.id AS chunk_id\n",
    "            ORDER BY score DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        similar = kg.query(search_query, \n",
    "                            params={\n",
    "                            'question_embedding': question_embedding,\n",
    "                            'top_k': top_k\n",
    "                            })\n",
    "        \n",
    "        print(f\"‚úÖ Recherche r√©ussie: {len(similar)} r√©sultats trouv√©s\")\n",
    "        \n",
    "        # Afficher les r√©sultats\n",
    "        for i, result in enumerate(similar, 1):\n",
    "            print(f\"   {i}. Score: {result['score']:.4f} | Source: {result['source']}\")\n",
    "            print(f\"      Text: {result['text'][:100]}...\")\n",
    "        \n",
    "        return similar\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur de recherche: {str(e)[:200]}...\")\n",
    "        print(\"üí° V√©rifiez que l'index 'GrahRAG' existe et que les embeddings sont g√©n√©r√©s\")\n",
    "        return []\n",
    "\n",
    "# Test de la fonction corrig√©e\n",
    "print(\"üß™ Test de la fonction de recherche vectorielle corrig√©e:\")\n",
    "test_results = neo4j_vector_search_robust(\"c'est quoi Luxchatgov\", top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c1a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ EXEMPLES D'UTILISATION DE LA RECHERCHE VECTORIELLE\n",
    "def demo_vector_search():\n",
    "    \"\"\"D√©monstration de diff√©rents types de recherches\"\"\"\n",
    "    \n",
    "    print(\"üéØ D√âMONSTRATION DE LA RECHERCHE VECTORIELLE\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Liste de questions de test\n",
    "    test_questions = [\n",
    "        \"Luxembourg\",\n",
    "        \"What is mentioned about technology?\",\n",
    "        \"Tell me about financial services\",\n",
    "        \"Any information about companies?\",\n",
    "        \"What data is available about regulations?\"\n",
    "    ]\n",
    "    \n",
    "    for i, question in enumerate(test_questions, 1):\n",
    "        print(f\"\\n{i}Ô∏è‚É£ QUESTION: {question}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        try:\n",
    "            results = neo4j_vector_search_robust(question, top_k=3)\n",
    "            \n",
    "            if results:\n",
    "                for j, result in enumerate(results, 1):\n",
    "                    score = result.get('score', 0)\n",
    "                    text = result.get('text', 'N/A')\n",
    "                    source = result.get('source', 'Unknown')\n",
    "                    \n",
    "                    print(f\"   üìÑ R√©sultat {j} (Score: {score:.3f})\")\n",
    "                    print(f\"   Source: {source}\")\n",
    "                    print(f\"   Texte: {text[:200]}...\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"   ‚ùå Aucun r√©sultat trouv√©\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erreur: {str(e)[:100]}...\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "\n",
    "# Ex√©cuter la d√©monstration\n",
    "demo_vector_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397b454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç RECHERCHE INTERACTIVE PERSONNALIS√âE\n",
    "def interactive_search():\n",
    "    \"\"\"Interface de recherche interactive\"\"\"\n",
    "    \n",
    "    print(\"üîç RECHERCHE INTERACTIVE DANS LE KNOWLEDGE GRAPH\")\n",
    "    print(\"=\" * 55)\n",
    "    print(\"Tapez votre question ou 'quit' pour arr√™ter\")\n",
    "    print(\"Exemples:\")\n",
    "    print(\"  ‚Ä¢ 'What is Luxembourg known for?'\")\n",
    "    print(\"  ‚Ä¢ 'Tell me about financial regulations'\")\n",
    "    print(\"  ‚Ä¢ 'Any mention of technology companies?'\")\n",
    "    print(\"\")\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            question = input(\"ü§î Votre question: \").strip()\n",
    "            \n",
    "            if question.lower() in ['quit', 'exit', 'stop', 'q']:\n",
    "                print(\"üëã Recherche termin√©e!\")\n",
    "                break\n",
    "                \n",
    "            if not question:\n",
    "                print(\"‚ö†Ô∏è Veuillez entrer une question valide\")\n",
    "                continue\n",
    "            \n",
    "            print(f\"\\nüîç Recherche en cours pour: '{question}'\")\n",
    "            print(\"-\" * 50)\n",
    "            \n",
    "            results = neo4j_vector_search_robust(question, top_k=3)\n",
    "            \n",
    "            if results:\n",
    "                print(f\"‚úÖ {len(results)} r√©sultats trouv√©s:\\n\")\n",
    "                \n",
    "                for i, result in enumerate(results, 1):\n",
    "                    score = result.get('score', 0)\n",
    "                    text = result.get('text', 'N/A')\n",
    "                    source = result.get('source', 'Unknown')\n",
    "                    \n",
    "                    print(f\"üìÑ R√âSULTAT {i}\")\n",
    "                    print(f\"   üìä Score de similarit√©: {score:.4f}\")\n",
    "                    print(f\"   üìÅ Source: {source}\")\n",
    "                    print(f\"   üìù Contenu: {text[:300]}...\")\n",
    "                    if len(text) > 300:\n",
    "                        print(\"       [...continu√©]\")\n",
    "                    print()\n",
    "            else:\n",
    "                print(\"‚ùå Aucun r√©sultat trouv√© pour cette question\")\n",
    "                print(\"üí° Essayez avec des mots-cl√©s diff√©rents\")\n",
    "            \n",
    "            print(\"=\" * 55)\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\nüëã Recherche interrompue par l'utilisateur\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Note: Cette fonction est interactive, d√©commentez la ligne suivante pour l'utiliser\n",
    "# interactive_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b034c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ RECHERCHE AVEC ANALYSE APPROFONDIE\n",
    "def advanced_vector_search(question, top_k=5, include_entities=True):\n",
    "    \"\"\"Recherche vectorielle avanc√©e avec analyse des entit√©s connexes\"\"\"\n",
    "    \n",
    "    print(f\"üîç RECHERCHE AVANC√âE: '{question}'\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. Recherche vectorielle standard\n",
    "    print(\"1Ô∏è‚É£ Recherche dans les chunks de texte:\")\n",
    "    chunk_results = neo4j_vector_search_robust(question, top_k=top_k)\n",
    "    \n",
    "    if chunk_results:\n",
    "        print(f\"   ‚úÖ {len(chunk_results)} chunks pertinents trouv√©s\")\n",
    "        \n",
    "        # Extraire les IDs des chunks les plus pertinents\n",
    "        relevant_chunk_ids = []\n",
    "        for result in chunk_results:\n",
    "            # R√©cup√©rer l'ID du chunk depuis Neo4j\n",
    "            chunk_query = \"\"\"\n",
    "                MATCH (c:Chunk) \n",
    "                WHERE c.text = $text \n",
    "                RETURN c.id as chunk_id\n",
    "                LIMIT 1\n",
    "            \"\"\"\n",
    "            chunk_id_result = kg.query(chunk_query, params={'text': result['text']})\n",
    "            if chunk_id_result:\n",
    "                relevant_chunk_ids.append(chunk_id_result[0]['chunk_id'])\n",
    "        \n",
    "        # 2. Trouver les entit√©s mentionn√©es dans ces chunks\n",
    "        if include_entities and relevant_chunk_ids:\n",
    "            print(\"\\n2Ô∏è‚É£ Entit√©s trouv√©es dans les chunks pertinents:\")\n",
    "            entities_query = \"\"\"\n",
    "                MATCH (c:Chunk)-[:MENTIONS]->(e:Entity)\n",
    "                WHERE c.id IN $chunk_ids\n",
    "                RETURN e.name as entity_name, e.type as entity_type, \n",
    "                       e.description as description, count(*) as mentions\n",
    "                ORDER BY mentions DESC, e.type\n",
    "            \"\"\"\n",
    "            \n",
    "            entities_results = kg.query(entities_query, params={'chunk_ids': relevant_chunk_ids})\n",
    "            \n",
    "            if entities_results:\n",
    "                print(f\"   ‚úÖ {len(entities_results)} entit√©s pertinentes:\")\n",
    "                \n",
    "                # Grouper par type\n",
    "                entities_by_type = {}\n",
    "                for entity in entities_results:\n",
    "                    entity_type = entity['entity_type']\n",
    "                    if entity_type not in entities_by_type:\n",
    "                        entities_by_type[entity_type] = []\n",
    "                    entities_by_type[entity_type].append(entity)\n",
    "                \n",
    "                for entity_type, entities in entities_by_type.items():\n",
    "                    print(f\"\\n   üìÇ {entity_type}:\")\n",
    "                    for entity in entities[:3]:  # Top 3 par type\n",
    "                        print(f\"      ‚Ä¢ {entity['entity_name']} ({entity['mentions']} mentions)\")\n",
    "                        if entity['description']:\n",
    "                            print(f\"        ‚Üí {entity['description']}\")\n",
    "            else:\n",
    "                print(\"   ‚ö†Ô∏è Aucune entit√© trouv√©e dans les chunks pertinents\")\n",
    "    \n",
    "    # 3. Affichage des r√©sultats principaux\n",
    "    print(\"\\n3Ô∏è‚É£ Chunks les plus pertinents:\")\n",
    "    if chunk_results:\n",
    "        for i, result in enumerate(chunk_results[:3], 1):\n",
    "            score = result.get('score', 0)\n",
    "            text = result.get('text', 'N/A')\n",
    "            source = result.get('source', 'Unknown')\n",
    "            \n",
    "            print(f\"\\n   üìÑ CHUNK {i} (Score: {score:.4f})\")\n",
    "            print(f\"   üìÅ Source: {source}\")\n",
    "            print(f\"   üìù Extrait: {text[:250]}...\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Aucun chunk pertinent trouv√©\")\n",
    "    \n",
    "    return {\n",
    "        'chunks': chunk_results,\n",
    "        'entities': entities_results if include_entities and 'entities_results' in locals() else [],\n",
    "        'question': question\n",
    "    }\n",
    "\n",
    "# Test de la recherche avanc√©e\n",
    "print(\"üß™ Test de la recherche avanc√©e:\")\n",
    "advanced_results = advanced_vector_search(\"financial services in Luxembourg\", top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3032cfce",
   "metadata": {},
   "source": [
    "### üéØ Guide d'utilisation de la recherche vectorielle\n",
    "\n",
    "Voici comment utiliser efficacement les fonctions de recherche que nous venons de cr√©er :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f509b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö GUIDE COMPLET D'UTILISATION DE LA RECHERCHE VECTORIELLE\n",
    "\n",
    "print(\"üìö GUIDE D'UTILISATION DE LA RECHERCHE VECTORIELLE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüîß FONCTIONS DISPONIBLES:\")\n",
    "print(\"1. neo4j_vector_search(question)           - Version originale\")\n",
    "print(\"2. neo4j_vector_search_robust(question)    - Version robuste avec fallback\")\n",
    "print(\"3. advanced_vector_search(question)        - Recherche + analyse des entit√©s\")\n",
    "print(\"4. demo_vector_search()                    - D√©monstration automatique\")\n",
    "print(\"5. interactive_search()                    - Interface interactive\")\n",
    "\n",
    "print(\"\\nüí° EXEMPLES D'UTILISATION:\")\n",
    "\n",
    "print(\"\\n1Ô∏è‚É£ RECHERCHE SIMPLE:\")\n",
    "print(\"   results = neo4j_vector_search_robust('Luxembourg financial sector')\")\n",
    "print(\"   # Retourne les chunks les plus similaires\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£ RECHERCHE AVEC NOMBRE DE R√âSULTATS:\")\n",
    "print(\"   results = neo4j_vector_search_robust('technology companies', top_k=10)\")\n",
    "print(\"   # Retourne les 10 meilleurs r√©sultats\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£ RECHERCHE AVANC√âE AVEC ENTIT√âS:\")\n",
    "print(\"   results = advanced_vector_search('banking regulations')\")\n",
    "print(\"   # Retourne chunks + entit√©s connexes\")\n",
    "\n",
    "print(\"\\n4Ô∏è‚É£ ACC√àS AUX R√âSULTATS:\")\n",
    "print(\"   for result in results:\")\n",
    "print(\"       score = result['score']      # Score de similarit√© (0-1)\")\n",
    "print(\"       text = result['text']        # Contenu du chunk\")\n",
    "print(\"       source = result['source']    # Nom du fichier source\")\n",
    "\n",
    "print(\"\\nüéØ TYPES DE QUESTIONS EFFICACES:\")\n",
    "print(\"‚Ä¢ Questions factuelles: 'What is Luxembourg known for?'\")\n",
    "print(\"‚Ä¢ Recherche de concepts: 'financial regulations'\")\n",
    "print(\"‚Ä¢ Recherche d'entit√©s: 'companies mentioned in the documents'\")\n",
    "print(\"‚Ä¢ Questions th√©matiques: 'technology and innovation'\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è CONSEILS POUR DE MEILLEURS R√âSULTATS:\")\n",
    "print(\"‚Ä¢ Utilisez des mots-cl√©s sp√©cifiques\")\n",
    "print(\"‚Ä¢ Posez des questions en anglais (si vos docs sont en anglais)\")\n",
    "print(\"‚Ä¢ Essayez diff√©rentes formulations\")\n",
    "print(\"‚Ä¢ Augmentez top_k pour plus de r√©sultats\")\n",
    "\n",
    "print(\"\\nüöÄ EXEMPLES CONCRETS √Ä TESTER:\")\n",
    "examples = [\n",
    "    \"Luxembourg banking sector\",\n",
    "    \"What regulations are mentioned?\",\n",
    "    \"Financial services overview\",\n",
    "    \"Technology companies\",\n",
    "    \"Economic policies\"\n",
    "]\n",
    "\n",
    "for i, example in enumerate(examples, 1):\n",
    "    print(f\"   {i}. '{example}'\")\n",
    "\n",
    "print(f\"\\nüîÑ POUR TESTER MAINTENANT:\")\n",
    "print(\"# D√©commentez et modifiez cette ligne:\")\n",
    "print(\"# results = neo4j_vector_search_robust('YOUR_QUESTION_HERE')\")\n",
    "print(\"# print(f'Found {len(results)} results')\")\n",
    "print(\"# for r in results[:3]: print(f'Score: {r[\\\"score\\\"]:.3f} - {r[\\\"text\\\"][:100]}...')\")\n",
    "\n",
    "# Exemple pratique pr√™t √† utiliser\n",
    "print(f\"\\nüß™ TEST RAPIDE:\")\n",
    "test_question = \"Luxembourg\"\n",
    "test_results = neo4j_vector_search_robust(test_question, top_k=2)\n",
    "if test_results:\n",
    "    print(f\"‚úÖ Test r√©ussi! {len(test_results)} r√©sultats pour '{test_question}'\")\n",
    "    for i, r in enumerate(test_results, 1):\n",
    "        print(f\"   {i}. Score: {r.get('score', 0):.3f} - {r.get('text', '')[:80]}...\")\n",
    "else:\n",
    "    print(f\"‚ùå Aucun r√©sultat pour '{test_question}' - v√©rifiez vos embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4472e4",
   "metadata": {},
   "source": [
    "## Extraction d'entit√©s avec OpenAI\n",
    "\n",
    "Maintenant que nous avons nos chunks, nous allons extraire les entit√©s importantes de chaque chunk en utilisant l'API OpenAI GPT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ebd134",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities_with_openai(text, chunk_id=None):\n",
    "    \"\"\"Extrait les entit√©s d'un texte avec OpenAI de fa√ßon simple\"\"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "Tu es un expert en extraction d'entit√©s. Analyse ce texte et identifie toutes les entit√©s importantes.\n",
    "\n",
    "Pour chaque entit√©, fournis :\n",
    "- name: le nom exact de l'entit√© \n",
    "- type: PERSON, ORGANIZATION, LOCATION, TECHNOLOGY, PRODUCT, CONCEPT, EVENT, DATE, MISC\n",
    "- description: br√®ve description contextuelle\n",
    "\n",
    "Texte √† analyser :\n",
    "---\n",
    "{text}\n",
    "---\n",
    "\n",
    "R√©ponds UNIQUEMENT en JSON valide :\n",
    "{{\n",
    "    \"entities\": [\n",
    "        {{\n",
    "            \"name\": \"nom_entit√©\",\n",
    "            \"type\": \"TYPE\",\n",
    "            \"description\": \"description courte\"\n",
    "        }}\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "    \n",
    "    # Appel OpenAI\n",
    "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)\n",
    "    response = llm.invoke(prompt)\n",
    "    \n",
    "    # Parser JSON\n",
    "    response_text = response.content.strip()\n",
    "    if response_text.startswith(\"```json\"):\n",
    "        response_text = response_text[7:-3]\n",
    "    elif response_text.startswith(\"```\"):\n",
    "        response_text = response_text[3:-3]\n",
    "    \n",
    "    result = json.loads(response_text)\n",
    "    entities = result.get('entities', [])\n",
    "    \n",
    "    # Ajouter m√©tadonn√©es simples\n",
    "    for entity in entities:\n",
    "        entity['chunk_id'] = chunk_id\n",
    "        entity['confidence'] = 0.8  # Score par d√©faut\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36daca9e",
   "metadata": {},
   "source": [
    "### Traitement Complet de Tous les PDFs\n",
    "\n",
    "‚ö†Ô∏è **Attention** : Cette cellule traite TOUS les chunks de TOUS les PDFs. Cela peut prendre beaucoup de temps et de cr√©dits OpenAI si vous avez beaucoup de documents. Utilisez la cellule suivante pour un test rapide d'abord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üö® CELLULE OPTIONNELLE : Traitement de TOUS les chunks\n",
    "sample_chunks = all_chunks  # ‚ö†Ô∏è Attention : peut √™tre tr√®s long !\n",
    "\n",
    "print(f\"üí° Configuration actuelle:\")\n",
    "print(f\"   üìÅ PDFs disponibles: {len(pdf_files)}\")\n",
    "print(f\"   üìÑ Total chunks: {len(all_chunks)}\")\n",
    "print(f\"   üß™ Chunks √† traiter: {len(sample_chunks) if 'sample_chunks' in locals() else 'Non d√©fini'}\")\n",
    "\n",
    "print(f\"\\nüí∞ Estimation des co√ªts OpenAI pour traitement complet:\")\n",
    "estimated_api_calls = len(all_chunks) * 2  # Entit√©s + embeddings\n",
    "print(f\"   ü§ñ Appels API estim√©s: {estimated_api_calls}\")\n",
    "print(f\"   üí∏ Co√ªt approximatif: ${estimated_api_calls * 0.001:.2f}\")\n",
    "\n",
    "print(f\"\\nüéØ Recommandation:\")\n",
    "if len(all_chunks) > 50:\n",
    "    print(f\"   ‚ö†Ô∏è Plus de 50 chunks d√©tect√©s - commencez par un √©chantillon\")\n",
    "else:\n",
    "    print(f\"   ‚úÖ Taille raisonnable - vous pouvez traiter tous les chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002df01c",
   "metadata": {},
   "source": [
    "### Extraction d'entit√©s depuis les chunks\n",
    "\n",
    "Maintenant, nous allons extraire les entit√©s de tous les chunks trait√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4a8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les entit√©s de tous les chunks (ou √©chantillon pour test)\n",
    "# Option 1: Traiter tous les chunks (peut √™tre long avec beaucoup de PDFs)\n",
    "# sample_chunks = all_chunks\n",
    "# Option 2: Traiter un √©chantillon pour tester rapidement\n",
    "sample_chunks = all_chunks[:20]  # Prendre les 20 premiers chunks\n",
    "\n",
    "all_entities = []\n",
    "\n",
    "print(f\"üîç Extraction d'entit√©s en cours pour {len(sample_chunks)} chunks...\\n\")\n",
    "\n",
    "for i, chunk_data in enumerate(sample_chunks):\n",
    "    print(f\"üìÑ Chunk {i+1}: {len(chunk_data['text'])} caract√®res\")\n",
    "    print(f\"Aper√ßu: {chunk_data['text'][:100]}...\")\n",
    "    \n",
    "    # Extraire les entit√©s\n",
    "    entities = extract_entities_with_openai(chunk_data['text'], chunk_data['id'])\n",
    "    \n",
    "    print(f\"‚úÖ {len(entities)} entit√©s trouv√©es\\n\")\n",
    "    \n",
    "    # Ajouter infos du chunk\n",
    "    for entity in entities:\n",
    "        entity['source_chunk'] = i\n",
    "        entity['filename'] = chunk_data['filename']\n",
    "        entity['doc_id'] = chunk_data['doc_id']\n",
    "        entity['text_preview'] = chunk_data['text'][:150]\n",
    "    \n",
    "    all_entities.extend(entities)\n",
    "\n",
    "print(f\"üéØ Total: {len(all_entities)} entit√©s extraites\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3897092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Afficher quelques exemples\n",
    "if len(all_entities) > 0:\n",
    "    print(f\"\\nüìã Exemples d'entit√©s extraites:\")\n",
    "    for i, entity in enumerate(all_entities[:3]):\n",
    "        print(f\"   {i+1}. {entity['name']} ({entity['type']})\")\n",
    "        print(f\"      Description: {entity['description']}\")\n",
    "        print(f\"      Source: {entity['filename']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1b94e",
   "metadata": {},
   "source": [
    "## G√©n√©ration des Embeddings avec OpenAI\n",
    "\n",
    "Maintenant, nous allons g√©n√©rer des embeddings vectoriels pour nos entit√©s et chunks afin d'activer la recherche s√©mantique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a85af3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    \"\"\"G√©n√®re des embeddings pour une liste de textes avec OpenAI\"\"\"\n",
    "    \n",
    "    # Initialiser le service d'embeddings OpenAI\n",
    "    embedding_service = OpenAIEmbeddings(model=model)\n",
    "    \n",
    "    print(f\"üîÑ G√©n√©ration de {len(texts)} embeddings avec {model}...\")\n",
    "    \n",
    "    # G√©n√©rer les embeddings\n",
    "    embeddings = embedding_service.embed_documents(texts)\n",
    "    \n",
    "    print(f\"‚úÖ Embeddings g√©n√©r√©s: {len(embeddings)} vecteurs de dimension {len(embeddings[0])}\")\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "def prepare_entity_texts(entities):\n",
    "    \"\"\"Pr√©pare les textes des entit√©s pour l'embedding\"\"\"\n",
    "    entity_texts = []\n",
    "    \n",
    "    for entity in entities:\n",
    "        # Combiner nom, type et description pour un embedding riche\n",
    "        text = f\"{entity['name']} ({entity['type']})\"\n",
    "        if entity.get('description'):\n",
    "            text += f\": {entity['description']}\"\n",
    "        entity_texts.append(text)\n",
    "    \n",
    "    return entity_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b801951",
   "metadata": {},
   "source": [
    "### G√©n√©ration des embeddings pour les entit√©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec6ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer les textes des entit√©s pour l'embedding\n",
    "entity_texts = prepare_entity_texts(all_entities)\n",
    "\n",
    "print(\"üìù Textes pr√©par√©s pour les entit√©s:\")\n",
    "for i, text in enumerate(entity_texts):\n",
    "    print(f\"   {i+1}. {text}\")\n",
    "\n",
    "# G√©n√©rer les embeddings des entit√©s\n",
    "entity_embeddings = generate_embeddings(entity_texts)\n",
    "\n",
    "# Associer les embeddings aux entit√©s\n",
    "for i, entity in enumerate(all_entities):\n",
    "    entity['embedding'] = entity_embeddings[i]\n",
    "    entity['embedding_dim'] = len(entity_embeddings[i])\n",
    "\n",
    "print(f\"‚úÖ Embeddings ajout√©s √† {len(all_entities)} entit√©s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519a8c40",
   "metadata": {},
   "source": [
    "### G√©n√©ration des embeddings pour les chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pr√©parer les textes des chunks pour l'embedding\n",
    "chunk_texts = [chunk_data['text'] for chunk_data in sample_chunks]\n",
    "\n",
    "print(f\"üìÑ Pr√©paration de {len(chunk_texts)} chunks pour embedding\")\n",
    "print(f\"Taille moyenne des chunks: {sum(len(text) for text in chunk_texts) // len(chunk_texts)} caract√®res\\n\")\n",
    "\n",
    "# G√©n√©rer les embeddings des chunks\n",
    "chunk_embeddings = generate_embeddings(chunk_texts)\n",
    "\n",
    "# Cr√©er une structure de donn√©es enrichie pour les chunks\n",
    "enriched_chunks = []\n",
    "for i, chunk_data in enumerate(sample_chunks):\n",
    "    enriched_chunk = {\n",
    "        'id': chunk_data['id'],\n",
    "        'text': chunk_data['text'],\n",
    "        'embedding': chunk_embeddings[i],\n",
    "        'embedding_dim': len(chunk_embeddings[i]),\n",
    "        'filename': chunk_data['filename'],\n",
    "        'doc_id': chunk_data['doc_id'],\n",
    "        'chunk_index': chunk_data['chunk_index'],\n",
    "        'text_length': len(chunk_data['text'])\n",
    "    }\n",
    "    enriched_chunks.append(enriched_chunk)\n",
    "\n",
    "print(f\"‚úÖ Embeddings g√©n√©r√©s pour {len(enriched_chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4bdff",
   "metadata": {},
   "source": [
    "## Cr√©ation du Knowledge Graph dans Neo4j\n",
    "\n",
    "Maintenant nous allons cr√©er notre knowledge graph directement dans Neo4j en utilisant des requ√™tes Cypher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01cc854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0644f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54c73f88",
   "metadata": {},
   "source": [
    "### 1. Cr√©ation des n≈ìuds Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22fc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nettoyer la base avant cr√©ation\n",
    "print(\"üßπ Nettoyage de la base Neo4j...\")\n",
    "kg.query(\"MATCH (n) DETACH DELETE n\")\n",
    "\n",
    "# Cr√©er les n≈ìuds Chunk avec le texte\n",
    "print(\"üìÑ Cr√©ation des n≈ìuds Chunk...\")\n",
    "\n",
    "for i, chunk in enumerate(enriched_chunks):\n",
    "    chunk_query = \"\"\"\n",
    "    CREATE (c:Chunk {\n",
    "        id: $chunk_id,\n",
    "        text: $text,\n",
    "        filename: $filename,\n",
    "        doc_id: $doc_id,\n",
    "        text_length: $text_length,\n",
    "        chunk_index: $chunk_index\n",
    "    })\n",
    "    \"\"\"\n",
    "    \n",
    "    kg.query(chunk_query, params={\n",
    "        \"chunk_id\": chunk['id'],\n",
    "        \"text\": chunk['text'],\n",
    "        \"filename\": chunk['filename'],\n",
    "        \"doc_id\": chunk['doc_id'],\n",
    "        \"text_length\": chunk['text_length'],\n",
    "        \"chunk_index\": chunk['chunk_index']\n",
    "    })\n",
    "\n",
    "print(f\"‚úÖ {len(enriched_chunks)} n≈ìuds Chunk cr√©√©s\")\n",
    "\n",
    "# V√©rifier la cr√©ation\n",
    "result = kg.query(\"MATCH (c:Chunk) RETURN count(c) as chunk_count\")\n",
    "print(f\"üìä N≈ìuds Chunk dans Neo4j: {result[0]['chunk_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4fc311",
   "metadata": {},
   "source": [
    "### 2. Cr√©ation des n≈ìuds Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fc55e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les n≈ìuds Entity\n",
    "print(\"üè∑Ô∏è Cr√©ation des n≈ìuds Entity...\")\n",
    "\n",
    "for entity in all_entities:\n",
    "    entity_query = \"\"\"\n",
    "    CREATE (e:Entity {\n",
    "        name: $name,\n",
    "        type: $type,\n",
    "        description: $description,\n",
    "        confidence: $confidence,\n",
    "        chunk_id: $chunk_id,\n",
    "        source_chunk: $source_chunk\n",
    "    })\n",
    "    \"\"\"\n",
    "    \n",
    "    kg.query(entity_query, params={\n",
    "        \"name\": entity['name'],\n",
    "        \"type\": entity['type'],\n",
    "        \"description\": entity.get('description', ''),\n",
    "        \"confidence\": entity.get('confidence', 0.8),\n",
    "        \"chunk_id\": entity.get('chunk_id', ''),\n",
    "        \"source_chunk\": entity.get('source_chunk', 0)\n",
    "    })\n",
    "\n",
    "print(f\"‚úÖ {len(all_entities)} n≈ìuds Entity cr√©√©s\")\n",
    "\n",
    "# V√©rifier la cr√©ation\n",
    "result = kg.query(\"MATCH (e:Entity) RETURN count(e) as entity_count\")\n",
    "print(f\"üìä N≈ìuds Entity dans Neo4j: {result[0]['entity_count']}\")\n",
    "\n",
    "# Voir la distribution par type\n",
    "type_result = kg.query(\"\"\"\n",
    "    MATCH (e:Entity) \n",
    "    RETURN e.type as type, count(e) as count \n",
    "    ORDER BY count DESC\n",
    "\"\"\")\n",
    "print(\"\\nüìà Distribution des entit√©s par type:\")\n",
    "for row in type_result:\n",
    "    print(f\"   {row['type']}: {row['count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f516f4",
   "metadata": {},
   "source": [
    "### 3. G√©n√©ration des embeddings avec genai.vector.encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03dec5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G√©n√©rer les embeddings pour les chunks directement dans Neo4j\n",
    "print(\"üîÑ G√©n√©ration des embeddings pour les chunks...\")\n",
    "\n",
    "# V√©rifier d'abord si genai.vector.encode est disponible\n",
    "try:\n",
    "    test_query = \"RETURN genai.vector.encode('test', 'OpenAI', {token: 'dummy'}) as test\"\n",
    "    kg.query(test_query)\n",
    "    genai_available = True\n",
    "    print(\"‚úÖ Utilisation de genai.vector.encode pour les embeddings\")\n",
    "except:\n",
    "    genai_available = False\n",
    "    print(\"‚ö†Ô∏è genai.vector.encode non disponible - utilisation d'embeddings pre-calcul√©s\")\n",
    "\n",
    "if genai_available:\n",
    "    # Utiliser genai.vector.encode si disponible\n",
    "    chunk_embedding_query = \"\"\"\n",
    "        MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
    "        WITH chunk, genai.vector.encode(\n",
    "          chunk.text, \n",
    "          \"OpenAI\", \n",
    "          {\n",
    "            token: $openAiApiKey, \n",
    "            endpoint: $openAiEndpoint\n",
    "          }) AS vector\n",
    "        CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
    "        RETURN count(chunk) as chunks_processed\n",
    "    \"\"\"\n",
    "    \n",
    "    result = kg.query(chunk_embedding_query, params={\n",
    "        \"openAiApiKey\": OPENAI_API_KEY, \n",
    "        \"openAiEndpoint\": OPENAI_ENDPOINT\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Embeddings Neo4j g√©n√©r√©s pour {result[0]['chunks_processed']} chunks\")\n",
    "    \n",
    "else:\n",
    "    # Utiliser les embeddings pr√©-calcul√©s\n",
    "    print(\"üîÑ Utilisation des embeddings pr√©-calcul√©s...\")\n",
    "    \n",
    "    for chunk in enriched_chunks:\n",
    "        if 'embedding' in chunk:\n",
    "            embedding_update_query = \"\"\"\n",
    "            MATCH (c:Chunk {id: $chunk_id})\n",
    "            CALL db.create.setNodeVectorProperty(c, \"textEmbedding\", $embedding)\n",
    "            RETURN c.id as updated_id\n",
    "            \"\"\"\n",
    "            \n",
    "            kg.query(embedding_update_query, params={\n",
    "                \"chunk_id\": chunk['id'],\n",
    "                \"embedding\": chunk['embedding']\n",
    "            })\n",
    "    \n",
    "    print(f\"‚úÖ Embeddings pr√©-calcul√©s ajout√©s pour {len(enriched_chunks)} chunks\")\n",
    "\n",
    "# M√™me logique pour les entit√©s\n",
    "print(\"üîÑ G√©n√©ration des embeddings pour les entit√©s...\")\n",
    "\n",
    "if genai_available:\n",
    "    entity_embedding_query = \"\"\"\n",
    "        MATCH (entity:Entity) WHERE entity.textEmbedding IS NULL\n",
    "        WITH entity, entity.name + \" (\" + entity.type + \"): \" + coalesce(entity.description, \"\") as entityText\n",
    "        WITH entity, genai.vector.encode(\n",
    "          entityText, \n",
    "          \"OpenAI\", \n",
    "          {\n",
    "            token: $openAiApiKey, \n",
    "            endpoint: $openAiEndpoint\n",
    "          }) AS vector\n",
    "        CALL db.create.setNodeVectorProperty(entity, \"textEmbedding\", vector)\n",
    "        RETURN count(entity) as entities_processed\n",
    "    \"\"\"\n",
    "    \n",
    "    result = kg.query(entity_embedding_query, params={\n",
    "        \"openAiApiKey\": OPENAI_API_KEY, \n",
    "        \"openAiEndpoint\": OPENAI_ENDPOINT\n",
    "    })\n",
    "    \n",
    "    print(f\"‚úÖ Embeddings Neo4j g√©n√©r√©s pour {result[0]['entities_processed']} entit√©s\")\n",
    "    \n",
    "else:\n",
    "    print(\"üîÑ Utilisation des embeddings pr√©-calcul√©s pour les entit√©s...\")\n",
    "    \n",
    "    for entity in all_entities:\n",
    "        if 'embedding' in entity:\n",
    "            entity_embedding_update_query = \"\"\"\n",
    "            MATCH (e:Entity {name: $name, type: $type})\n",
    "            CALL db.create.setNodeVectorProperty(e, \"textEmbedding\", $embedding)\n",
    "            RETURN e.name as updated_name\n",
    "            \"\"\"\n",
    "            \n",
    "            kg.query(entity_embedding_update_query, params={\n",
    "                \"name\": entity['name'],\n",
    "                \"type\": entity['type'],\n",
    "                \"embedding\": entity['embedding']\n",
    "            })\n",
    "    \n",
    "    print(f\"‚úÖ Embeddings pr√©-calcul√©s ajout√©s pour {len(all_entities)} entit√©s\")\n",
    "\n",
    "# V√©rifier les embeddings\n",
    "verification_query = \"\"\"\n",
    "    MATCH (n) \n",
    "    WHERE n.textEmbedding IS NOT NULL \n",
    "    RETURN labels(n)[0] as nodeType, count(n) as count, \n",
    "           size(n.textEmbedding) as embeddingDim\n",
    "\"\"\"\n",
    "\n",
    "verification_result = kg.query(verification_query)\n",
    "print(\"\\nüìä V√©rification des embeddings:\")\n",
    "for row in verification_result:\n",
    "    print(f\"   {row['nodeType']}: {row['count']} n≈ìuds, dimension {row['embeddingDim']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1954a8",
   "metadata": {},
   "source": [
    "### 4. Cr√©ation des relations MENTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ffb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©er les relations MENTIONS entre Chunk et Entity\n",
    "print(\"üîó Cr√©ation des relations MENTIONS...\")\n",
    "\n",
    "mentions_created = 0\n",
    "\n",
    "for entity in all_entities:\n",
    "    # Cr√©er la relation entre le chunk source et l'entit√©\n",
    "    mentions_query = \"\"\"\n",
    "    MATCH (c:Chunk {id: $chunk_id})\n",
    "    MATCH (e:Entity {name: $entity_name, type: $entity_type})\n",
    "    CREATE (c)-[:MENTIONS {confidence: $confidence}]->(e)\n",
    "    \"\"\"\n",
    "    \n",
    "    kg.query(mentions_query, params={\n",
    "        \"chunk_id\": entity.get('chunk_id', ''),\n",
    "        \"entity_name\": entity['name'],\n",
    "        \"entity_type\": entity['type'],\n",
    "        \"confidence\": entity.get('confidence', 0.8)\n",
    "    })\n",
    "    mentions_created += 1\n",
    "\n",
    "print(f\"‚úÖ {mentions_created} relations MENTIONS cr√©√©es\")\n",
    "\n",
    "# Cr√©er des relations NEXT entre chunks cons√©cutifs\n",
    "print(\"üîó Cr√©ation des relations NEXT entre chunks...\")\n",
    "\n",
    "next_query = \"\"\"\n",
    "MATCH (c1:Chunk), (c2:Chunk)\n",
    "WHERE c1.chunk_index + 1 = c2.chunk_index\n",
    "CREATE (c1)-[:NEXT]->(c2)\n",
    "\"\"\"\n",
    "\n",
    "kg.query(next_query)\n",
    "\n",
    "# V√©rifier les relations\n",
    "relations_result = kg.query(\"\"\"\n",
    "    MATCH ()-[r]->() \n",
    "    RETURN type(r) as relationType, count(r) as count\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìä Relations cr√©√©es:\")\n",
    "for row in relations_result:\n",
    "    print(f\"   {row['relationType']}: {row['count']}\")\n",
    "\n",
    "print(f\"\\nüéØ Knowledge Graph cr√©√© avec succ√®s!\")\n",
    "print(f\"   N≈ìuds Chunk: {len(enriched_chunks)}\")\n",
    "print(f\"   N≈ìuds Entity: {len(all_entities)}\")\n",
    "print(f\"   Relations MENTIONS: {mentions_created}\")\n",
    "print(f\"   Relations NEXT: {len(enriched_chunks)-1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803996dc",
   "metadata": {},
   "source": [
    "## üîó Relations Avanc√©es Inspir√©es de L5\n",
    "\n",
    "Nous allons maintenant cr√©er des relations plus sophistiqu√©es bas√©es sur les exemples du Lab 5, adapt√©es √† notre structure de donn√©es PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "4b3d9e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Cr√©ation des n≈ìuds Document pour chaque PDF...\n",
      "   üìö 10 documents uniques trouv√©s\n",
      "   üìö 10 documents uniques trouv√©s\n",
      "‚úÖ 10 n≈ìuds Document cr√©√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: cdaa8e23...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: adcba2cb...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: f65e7891...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: 042b1062...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: a8d0c1d8...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: 03c6a6be...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: 3fef7c6a...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: 2cbf6174...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: d0d54f67...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: c4fbb0ae...)\n",
      "‚úÖ 10 n≈ìuds Document cr√©√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: cdaa8e23...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: adcba2cb...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: f65e7891...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: 042b1062...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: a8d0c1d8...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: 03c6a6be...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: 3fef7c6a...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: 2cbf6174...)\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf (ID: d0d54f67...)\n",
      "   üìÑ rapport-activite-2024-fin.pdf (ID: c4fbb0ae...)\n"
     ]
    }
   ],
   "source": [
    "# üìã CR√âATION DES N≈íUDS DOCUMENT\n",
    "# Similaire aux n≈ìuds Form dans L5, nous cr√©ons des n≈ìuds Document pour repr√©senter chaque PDF\n",
    "\n",
    "print(\"üìÑ Cr√©ation des n≈ìuds Document pour chaque PDF...\")\n",
    "\n",
    "# R√©cup√©rer les informations uniques des documents\n",
    "doc_info_query = \"\"\"\n",
    "MATCH (c:Chunk) \n",
    "WITH c.filename as filename, c.doc_id as doc_id\n",
    "RETURN DISTINCT filename, doc_id\n",
    "\"\"\"\n",
    "\n",
    "doc_infos = kg.query(doc_info_query)\n",
    "print(f\"   üìö {len(doc_infos)} documents uniques trouv√©s\")\n",
    "\n",
    "# Cr√©er un n≈ìud Document pour chaque PDF\n",
    "for doc_info in doc_infos:\n",
    "    create_doc_query = \"\"\"\n",
    "    MERGE (d:Document {doc_id: $doc_id})\n",
    "    ON CREATE SET \n",
    "        d.filename = $filename,\n",
    "        d.source = $filename,\n",
    "        d.type = 'PDF'\n",
    "    \"\"\"\n",
    "    \n",
    "    kg.query(create_doc_query, params={\n",
    "        'doc_id': doc_info['doc_id'],\n",
    "        'filename': doc_info['filename']\n",
    "    })\n",
    "\n",
    "# V√©rifier la cr√©ation\n",
    "doc_count = kg.query(\"MATCH (d:Document) RETURN count(d) as count\")[0]['count']\n",
    "print(f\"‚úÖ {doc_count} n≈ìuds Document cr√©√©s\")\n",
    "\n",
    "# Afficher les documents cr√©√©s\n",
    "docs = kg.query(\"MATCH (d:Document) RETURN d.filename as filename, d.doc_id as doc_id\")\n",
    "for doc in docs:\n",
    "    print(f\"   üìÑ {doc['filename']} (ID: {doc['doc_id'][:8]}...)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "4375937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Cr√©ation des relations PART_OF entre Chunks et Documents...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 1416 relations PART_OF cr√©√©es\n",
      "\n",
      "üìä Distribution des chunks par document:\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 1401 chunks\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 15 chunks\n",
      "\n",
      "üìä Distribution des chunks par document:\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 1401 chunks\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 15 chunks\n"
     ]
    }
   ],
   "source": [
    "# üîó RELATIONS PART_OF - Chunks appartiennent aux Documents\n",
    "# Similaire aux relations entre Chunks et Form dans L5\n",
    "\n",
    "print(\"üîó Cr√©ation des relations PART_OF entre Chunks et Documents...\")\n",
    "\n",
    "part_of_query = \"\"\"\n",
    "MATCH (c:Chunk), (d:Document)\n",
    "WHERE c.doc_id = d.doc_id\n",
    "MERGE (c)-[r:PART_OF]->(d)\n",
    "RETURN count(r) as relations_created\n",
    "\"\"\"\n",
    "\n",
    "result = kg.query(part_of_query)\n",
    "print(f\"‚úÖ {result[0]['relations_created']} relations PART_OF cr√©√©es\")\n",
    "\n",
    "# V√©rifier les relations\n",
    "verification_query = \"\"\"\n",
    "MATCH (c:Chunk)-[:PART_OF]->(d:Document)\n",
    "RETURN d.filename as document, count(c) as chunk_count\n",
    "ORDER BY chunk_count DESC\n",
    "\"\"\"\n",
    "\n",
    "doc_chunks = kg.query(verification_query)\n",
    "print(f\"\\nüìä Distribution des chunks par document:\")\n",
    "for doc in doc_chunks:\n",
    "    print(f\"   üìÑ {doc['document']}: {doc['chunk_count']} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "349f37b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Cr√©ation des relations FIRST_CHUNK...\n",
      "‚úÖ 10 relations FIRST_CHUNK cr√©√©es\n",
      "‚úÖ 10 relations FIRST_CHUNK cr√©√©es\n",
      "\n",
      "üìã Premiers chunks de chaque document:\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: bfb5ab14-dbfb-45e7-9d92-70f27ab7e52e\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: 57e622ff-cc6a-4331-9965-5252e45f3759\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: 238803c8-933e-419b-aa73-5a346e3c88be\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: 1dd59428-04a6-4262-bb49-56f240a0971b\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: 105aca99-ee63-4165-8ac1-762786cdc71b\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: c871a497-4283-48ff-a050-4129fed66dcf\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: eaf5770d-c8d2-488d-8f48-67c6c0d6749b\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: 16024664-a4a9-408d-aa67-cc0065834f0a\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: f99b7d70-0b34-4acf-a862-249fd6f8d103\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: a3d6949e-0fba-40e3-b4de-174193795ca9\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "\n",
      "üìã Premiers chunks de chaque document:\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: bfb5ab14-dbfb-45e7-9d92-70f27ab7e52e\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: 57e622ff-cc6a-4331-9965-5252e45f3759\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: 238803c8-933e-419b-aa73-5a346e3c88be\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: 1dd59428-04a6-4262-bb49-56f240a0971b\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: 105aca99-ee63-4165-8ac1-762786cdc71b\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: c871a497-4283-48ff-a050-4129fed66dcf\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: eaf5770d-c8d2-488d-8f48-67c6c0d6749b\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: 16024664-a4a9-408d-aa67-cc0065834f0a\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      ID: f99b7d70-0b34-4acf-a862-249fd6f8d103\n",
      "      Aper√ßu: Technical Homework Assignment:  \n",
      " \n",
      " \n",
      "GraphRAG Knowledge Graph endpoint + Streamlit \n",
      "frontend \n",
      "Object...\n",
      "\n",
      "   üìÑ rapport-activite-2024-fin.pdf\n",
      "      ID: a3d6949e-0fba-40e3-b4de-174193795ca9\n",
      "      Aper√ßu: RAPPORT \n",
      "D‚ÄôACTIVIT√â 2024 \n",
      "Minist√®re de la Digitalisation...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# üè∑Ô∏è RELATIONS FIRST_CHUNK - Premier chunk de chaque document\n",
    "# Similaire aux relations SECTION dans L5\n",
    "\n",
    "print(\"üè∑Ô∏è Cr√©ation des relations FIRST_CHUNK...\")\n",
    "\n",
    "first_chunk_query = \"\"\"\n",
    "MATCH (c:Chunk), (d:Document)\n",
    "WHERE c.doc_id = d.doc_id \n",
    "    AND c.chunk_index = 0\n",
    "MERGE (d)-[r:FIRST_CHUNK]->(c)\n",
    "RETURN count(r) as relations_created\n",
    "\"\"\"\n",
    "\n",
    "result = kg.query(first_chunk_query)\n",
    "print(f\"‚úÖ {result[0]['relations_created']} relations FIRST_CHUNK cr√©√©es\")\n",
    "\n",
    "# V√©rifier les premiers chunks\n",
    "first_chunks = kg.query(\"\"\"\n",
    "MATCH (d:Document)-[:FIRST_CHUNK]->(c:Chunk)\n",
    "RETURN d.filename as document, c.id as chunk_id, \n",
    "       substring(c.text, 0, 100) as preview\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nüìã Premiers chunks de chaque document:\")\n",
    "for chunk in first_chunks:\n",
    "    print(f\"   üìÑ {chunk['document']}\")\n",
    "    print(f\"      ID: {chunk['chunk_id']}\")\n",
    "    print(f\"      Aper√ßu: {chunk['preview']}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f040fe68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Am√©lioration des relations NEXT avec apoc.nodes.link...\n",
      "‚úÖ APOC disponible: 2025.08.0\n",
      "üîÑ Recr√©ation des relations NEXT avec APOC...\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 17 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 17 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "‚úÖ Relations NEXT am√©lior√©es avec APOC\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf: 3 chunks li√©s\n",
      "   üìÑ rapport-activite-2024-fin.pdf: 346 chunks li√©s\n",
      "‚úÖ Relations NEXT am√©lior√©es avec APOC\n",
      "\n",
      "üìä Total relations NEXT: 1406\n",
      "\n",
      "üìä Total relations NEXT: 1406\n"
     ]
    }
   ],
   "source": [
    "# üîó AM√âLIORATION DES RELATIONS NEXT AVEC APOC (si disponible)\n",
    "# Utilisation d'apoc.nodes.link comme dans L5 pour cr√©er des liens plus robustes\n",
    "\n",
    "print(\"üîó Am√©lioration des relations NEXT avec apoc.nodes.link...\")\n",
    "\n",
    "# V√©rifier si APOC est disponible\n",
    "try:\n",
    "    test_apoc = kg.query(\"RETURN apoc.version() as version\")\n",
    "    apoc_available = True\n",
    "    print(f\"‚úÖ APOC disponible: {test_apoc[0]['version']}\")\n",
    "except:\n",
    "    apoc_available = False\n",
    "    print(\"‚ö†Ô∏è APOC non disponible - utilisation de la m√©thode standard\")\n",
    "\n",
    "if apoc_available:\n",
    "    # Utiliser apoc.nodes.link pour chaque document s√©par√©ment\n",
    "    print(\"üîÑ Recr√©ation des relations NEXT avec APOC...\")\n",
    "    \n",
    "    # D'abord supprimer les anciennes relations NEXT\n",
    "    kg.query(\"MATCH ()-[r:NEXT]->() DELETE r\")\n",
    "    \n",
    "    # Cr√©er des relations NEXT pour chaque document avec APOC\n",
    "    documents = kg.query(\"MATCH (d:Document) RETURN d.doc_id as doc_id, d.filename as filename\")\n",
    "    \n",
    "    for doc in documents:\n",
    "        apoc_next_query = \"\"\"\n",
    "        MATCH (c:Chunk)\n",
    "        WHERE c.doc_id = $doc_id\n",
    "        WITH c ORDER BY c.chunk_index ASC\n",
    "        WITH collect(c) as chunk_list\n",
    "        CALL apoc.nodes.link(chunk_list, \"NEXT\", {avoidDuplicates: true})\n",
    "        RETURN size(chunk_list) as chunks_linked\n",
    "        \"\"\"\n",
    "        \n",
    "        result = kg.query(apoc_next_query, params={'doc_id': doc['doc_id']})\n",
    "        print(f\"   üìÑ {doc['filename']}: {result[0]['chunks_linked']} chunks li√©s\")\n",
    "    \n",
    "    print(\"‚úÖ Relations NEXT am√©lior√©es avec APOC\")\n",
    "else:\n",
    "    print(\"‚úÖ Relations NEXT existantes conserv√©es\")\n",
    "\n",
    "# V√©rifier les relations NEXT\n",
    "next_count = kg.query(\"MATCH ()-[r:NEXT]->() RETURN count(r) as count\")[0]['count']\n",
    "print(f\"\\nüìä Total relations NEXT: {next_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ff99f32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ù Cr√©ation de relations entre entit√©s...\n",
      "‚úÖ 447 relations CO_OCCURS cr√©√©es\n",
      "‚úÖ 850 relations SAME_TYPE cr√©√©es\n",
      "‚úÖ 447 relations CO_OCCURS cr√©√©es\n",
      "‚úÖ 850 relations SAME_TYPE cr√©√©es\n",
      "‚úÖ 862 relations RELATED_TO cr√©√©es\n",
      "\n",
      "üìä R√©sum√© des relations entre entit√©s:\n",
      "   ü§ù Co-occurrence: 447\n",
      "   üè∑Ô∏è M√™me type: 850\n",
      "   üîó Proximit√©: 862\n",
      "‚úÖ 862 relations RELATED_TO cr√©√©es\n",
      "\n",
      "üìä R√©sum√© des relations entre entit√©s:\n",
      "   ü§ù Co-occurrence: 447\n",
      "   üè∑Ô∏è M√™me type: 850\n",
      "   üîó Proximit√©: 862\n"
     ]
    }
   ],
   "source": [
    "# ü§ù RELATIONS ENTRE ENTIT√âS - Co-occurrence et Similarit√©\n",
    "# Cr√©er des relations entre entit√©s qui apparaissent dans le m√™me chunk ou des chunks similaires\n",
    "\n",
    "print(\"ü§ù Cr√©ation de relations entre entit√©s...\")\n",
    "\n",
    "# 1. Relations CO_OCCURS - Entit√©s qui apparaissent dans le m√™me chunk\n",
    "co_occurrence_query = \"\"\"\n",
    "MATCH (e1:Entity)<-[:MENTIONS]-(c:Chunk)-[:MENTIONS]->(e2:Entity)\n",
    "WHERE e1.name < e2.name  // √âviter les doublons\n",
    "MERGE (e1)-[r:CO_OCCURS]->(e2)\n",
    "ON CREATE SET r.shared_chunks = 1\n",
    "ON MATCH SET r.shared_chunks = r.shared_chunks + 1\n",
    "RETURN count(r) as co_occurrence_relations\n",
    "\"\"\"\n",
    "\n",
    "co_occurs = kg.query(co_occurrence_query)\n",
    "print(f\"‚úÖ {co_occurs[0]['co_occurrence_relations']} relations CO_OCCURS cr√©√©es\")\n",
    "\n",
    "# 2. Relations SAME_TYPE - Entit√©s du m√™me type\n",
    "same_type_query = \"\"\"\n",
    "MATCH (e1:Entity), (e2:Entity)\n",
    "WHERE e1.type = e2.type \n",
    "    AND e1.name < e2.name  // √âviter les doublons\n",
    "    AND e1.type IN ['PERSON', 'ORGANIZATION', 'LOCATION']  // Limiter aux types importants\n",
    "MERGE (e1)-[r:SAME_TYPE {type: e1.type}]->(e2)\n",
    "RETURN count(r) as same_type_relations\n",
    "\"\"\"\n",
    "\n",
    "same_type = kg.query(same_type_query)\n",
    "print(f\"‚úÖ {same_type[0]['same_type_relations']} relations SAME_TYPE cr√©√©es\")\n",
    "\n",
    "# 3. Relations RELATED_TO - Entit√©s li√©es par proximit√© dans le texte\n",
    "proximity_query = \"\"\"\n",
    "MATCH (c1:Chunk)-[:NEXT]->(c2:Chunk)\n",
    "MATCH (c1)-[:MENTIONS]->(e1:Entity)\n",
    "MATCH (c2)-[:MENTIONS]->(e2:Entity)\n",
    "WHERE e1.name <> e2.name\n",
    "MERGE (e1)-[r:RELATED_TO]->(e2)\n",
    "ON CREATE SET r.proximity_count = 1\n",
    "ON MATCH SET r.proximity_count = r.proximity_count + 1\n",
    "RETURN count(r) as proximity_relations\n",
    "\"\"\"\n",
    "\n",
    "proximity = kg.query(proximity_query)\n",
    "print(f\"‚úÖ {proximity[0]['proximity_relations']} relations RELATED_TO cr√©√©es\")\n",
    "\n",
    "print(f\"\\nüìä R√©sum√© des relations entre entit√©s:\")\n",
    "print(f\"   ü§ù Co-occurrence: {co_occurs[0]['co_occurrence_relations']}\")\n",
    "print(f\"   üè∑Ô∏è M√™me type: {same_type[0]['same_type_relations']}\")\n",
    "print(f\"   üîó Proximit√©: {proximity[0]['proximity_relations']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "4da3965e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä EXEMPLES DE REQU√äTES AVANC√âES\n",
      "==================================================\n",
      "\n",
      "1Ô∏è‚É£ Fen√™tre de chunks (contexte √©tendu):\n",
      "   üìÑ Contexte √©tendu autour du mot 'Luxembourg':\n",
      "   [23] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "8...\n",
      "   [23] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "8...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [25] bas√©e sur des projets innovants, la valorisation des donn√©es et l'application responsable et avantag...\n",
      "   [25] bas√©e sur des projets innovants, la valorisation des donn√©es et l'application responsable et avantag...\n",
      "\n",
      "2Ô∏è‚É£ Navigation document -> chunks -> entit√©s:\n",
      "   üóÇÔ∏è Structure: Document -> Chunks -> Entit√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      Chunk[0] -> Streamlit (TECHNOLOGY)\n",
      "      Chunk[0] -> GraphRAG Knowledge Graph (TECHNOLOGY)\n",
      "      Chunk[0] -> bearer token (TECHNOLOGY)\n",
      "      Chunk[0] -> bearer token (TECHNOLOGY)\n",
      "      Chunk[0] -> Markdown (TECHNOLOGY)\n",
      "      Chunk[0] -> FastAPI (TECHNOLOGY)\n",
      "      Chunk[0] -> Streamlit (TECHNOLOGY)\n",
      "      Chunk[0] -> concurrent.futures (TECHNOLOGY)\n",
      "      Chunk[1] -> bearer token (TECHNOLOGY)\n",
      "      Chunk[1] -> Text embeddings (TECHNOLOGY)\n",
      "\n",
      "3Ô∏è‚É£ Entit√©s qui apparaissent souvent ensemble:\n",
      "   üìÑ Contexte √©tendu autour du mot 'Luxembourg':\n",
      "   [23] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "8...\n",
      "   [23] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "8...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [24] Rapport d‚Äôactivit√© 2024 \n",
      "Minist√®re de la Digitalisation  \n",
      " \n",
      "9 \n",
      "Trois strat√©gies nationales : donn√©es...\n",
      "   [25] bas√©e sur des projets innovants, la valorisation des donn√©es et l'application responsable et avantag...\n",
      "   [25] bas√©e sur des projets innovants, la valorisation des donn√©es et l'application responsable et avantag...\n",
      "\n",
      "2Ô∏è‚É£ Navigation document -> chunks -> entit√©s:\n",
      "   üóÇÔ∏è Structure: Document -> Chunks -> Entit√©s\n",
      "   üìÑ HW_GRAG_KnowledgeGraph_Solution_Engineer.pdf\n",
      "      Chunk[0] -> Streamlit (TECHNOLOGY)\n",
      "      Chunk[0] -> GraphRAG Knowledge Graph (TECHNOLOGY)\n",
      "      Chunk[0] -> bearer token (TECHNOLOGY)\n",
      "      Chunk[0] -> bearer token (TECHNOLOGY)\n",
      "      Chunk[0] -> Markdown (TECHNOLOGY)\n",
      "      Chunk[0] -> FastAPI (TECHNOLOGY)\n",
      "      Chunk[0] -> Streamlit (TECHNOLOGY)\n",
      "      Chunk[0] -> concurrent.futures (TECHNOLOGY)\n",
      "      Chunk[1] -> bearer token (TECHNOLOGY)\n",
      "      Chunk[1] -> Text embeddings (TECHNOLOGY)\n",
      "\n",
      "3Ô∏è‚É£ Entit√©s qui apparaissent souvent ensemble:\n",
      "   ü§ù Paires d'entit√©s les plus li√©es:\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "\n",
      "==================================================\n",
      "‚úÖ Exemples de requ√™tes ex√©cut√©s avec succ√®s!\n",
      "   ü§ù Paires d'entit√©s les plus li√©es:\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "   Minist√®re de la Digitalisation (ORGANIZATION) ‚Üî Rapport d‚Äôactivit√© 2024 (CONCEPT) [6x]\n",
      "\n",
      "==================================================\n",
      "‚úÖ Exemples de requ√™tes ex√©cut√©s avec succ√®s!\n"
     ]
    }
   ],
   "source": [
    "# üìä REQU√äTES D'EXEMPLE INSPIR√âES DE L5\n",
    "# D√©monstration des nouvelles relations avec des requ√™tes Cypher avanc√©es\n",
    "\n",
    "print(\"üìä EXEMPLES DE REQU√äTES AVANC√âES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 1. Fen√™tre de chunks autour d'un chunk sp√©cifique (comme dans L5)\n",
    "print(\"\\n1Ô∏è‚É£ Fen√™tre de chunks (contexte √©tendu):\")\n",
    "\n",
    "window_query = \"\"\"\n",
    "MATCH (c:Chunk)\n",
    "WHERE c.text CONTAINS 'Luxembourg'\n",
    "WITH c LIMIT 1\n",
    "MATCH window = (prev:Chunk)-[:NEXT*0..1]->(c)-[:NEXT*0..1]->(next:Chunk)\n",
    "WITH nodes(window) as chunk_window, c\n",
    "UNWIND chunk_window as chunk_node\n",
    "RETURN chunk_node.chunk_index as index, \n",
    "       substring(chunk_node.text, 0, 100) as text_preview\n",
    "ORDER BY index\n",
    "\"\"\"\n",
    "\n",
    "window_result = kg.query(window_query)\n",
    "if window_result:\n",
    "    print(\"   üìÑ Contexte √©tendu autour du mot 'Luxembourg':\")\n",
    "    for chunk in window_result:\n",
    "        print(f\"   [{chunk['index']}] {chunk['text_preview']}...\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Aucun chunk contenant 'Luxembourg' trouv√©\")\n",
    "\n",
    "# 2. Navigation dans la structure de document\n",
    "print(\"\\n2Ô∏è‚É£ Navigation document -> chunks -> entit√©s:\")\n",
    "\n",
    "navigation_query = \"\"\"\n",
    "MATCH (d:Document)-[:FIRST_CHUNK]->(first:Chunk)\n",
    "MATCH (first)-[:NEXT*0..2]->(c:Chunk)-[:MENTIONS]->(e:Entity)\n",
    "WHERE d.filename CONTAINS '.pdf'\n",
    "RETURN d.filename as document, \n",
    "       c.chunk_index as chunk_index,\n",
    "       e.name as entity, \n",
    "       e.type as entity_type\n",
    "ORDER BY document, chunk_index\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "navigation_result = kg.query(navigation_query)\n",
    "print(\"   üóÇÔ∏è Structure: Document -> Chunks -> Entit√©s\")\n",
    "current_doc = None\n",
    "for item in navigation_result:\n",
    "    if item['document'] != current_doc:\n",
    "        current_doc = item['document']\n",
    "        print(f\"   üìÑ {current_doc}\")\n",
    "    print(f\"      Chunk[{item['chunk_index']}] -> {item['entity']} ({item['entity_type']})\")\n",
    "\n",
    "# 3. Entit√©s co-occurrentes les plus fr√©quentes\n",
    "print(\"\\n3Ô∏è‚É£ Entit√©s qui apparaissent souvent ensemble:\")\n",
    "\n",
    "co_occurrence_stats = \"\"\"\n",
    "MATCH (e1:Entity)-[r:CO_OCCURS]->(e2:Entity)\n",
    "WHERE r.shared_chunks > 1\n",
    "RETURN e1.name as entity1, e1.type as type1,\n",
    "       e2.name as entity2, e2.type as type2,\n",
    "       r.shared_chunks as frequency\n",
    "ORDER BY frequency DESC\n",
    "LIMIT 5\n",
    "\"\"\"\n",
    "\n",
    "co_occurrence_result = kg.query(co_occurrence_stats)\n",
    "if co_occurrence_result:\n",
    "    print(\"   ü§ù Paires d'entit√©s les plus li√©es:\")\n",
    "    for pair in co_occurrence_result:\n",
    "        print(f\"   {pair['entity1']} ({pair['type1']}) ‚Üî {pair['entity2']} ({pair['type2']}) [{pair['frequency']}x]\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è Aucune co-occurrence multiple trouv√©e\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"‚úÖ Exemples de requ√™tes ex√©cut√©s avec succ√®s!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "34659a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ CONFIGURATION DE LA R√âCUP√âRATION AVEC FEN√äTRE DE CONTEXTE\n",
      "============================================================\n",
      "üìã Requ√™te de r√©cup√©ration avec fen√™tre cr√©√©e!\n",
      "üí° Cette requ√™te r√©cup√®re le contexte √©tendu autour de chaque chunk trouv√©\n",
      "üí° Similaire aux fen√™tres de r√©cup√©ration du Lab 5\n",
      "\n",
      "üß™ TEST DE LA R√âCUP√âRATION AVEC FEN√äTRE\n",
      "----------------------------------------\n",
      "‚úÖ Test r√©ussi!\n",
      "   üìä Taille de fen√™tre: 3 chunks\n",
      "   üéØ Chunk central: index 24\n",
      "   üìÑ Source: rapport-activite-2024-fin.pdf\n",
      "\n",
      "‚úÖ Configuration de r√©cup√©ration avec fen√™tre pr√™te!\n",
      "üí° Peut √™tre utilis√©e avec Neo4jVector.from_existing_index()\n",
      "üí° Am√©liore le contexte des r√©ponses RAG\n",
      "‚úÖ Test r√©ussi!\n",
      "   üìä Taille de fen√™tre: 3 chunks\n",
      "   üéØ Chunk central: index 24\n",
      "   üìÑ Source: rapport-activite-2024-fin.pdf\n",
      "\n",
      "‚úÖ Configuration de r√©cup√©ration avec fen√™tre pr√™te!\n",
      "üí° Peut √™tre utilis√©e avec Neo4jVector.from_existing_index()\n",
      "üí° Am√©liore le contexte des r√©ponses RAG\n"
     ]
    }
   ],
   "source": [
    "# üöÄ REQU√äTE DE R√âCUP√âRATION AVANC√âE AVEC FEN√äTRE\n",
    "# Impl√©mentation d'une requ√™te de r√©cup√©ration avec fen√™tre de contexte comme dans L5\n",
    "\n",
    "print(\"üöÄ CONFIGURATION DE LA R√âCUP√âRATION AVEC FEN√äTRE DE CONTEXTE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Requ√™te de r√©cup√©ration avec fen√™tre inspir√©e de L5\n",
    "retrieval_query_with_window = \"\"\"\n",
    "MATCH window = (prev:Chunk)-[:NEXT*0..1]->(node)-[:NEXT*0..1]->(next:Chunk)\n",
    "WHERE node.doc_id = prev.doc_id OR prev IS NULL\n",
    "  AND node.doc_id = next.doc_id OR next IS NULL\n",
    "WITH node, score, window as contextWindow \n",
    "  ORDER BY length(window) DESC LIMIT 1\n",
    "WITH nodes(contextWindow) as chunkList, node, score\n",
    "  UNWIND chunkList as chunkNode\n",
    "WITH collect(chunkNode.text) as textList, node, score\n",
    "RETURN apoc.text.join(textList, \" \\\\n\\\\n--- CHUNK SEPARATOR ---\\\\n\\\\n \") as text,\n",
    "    score,\n",
    "    {source: node.filename, chunk_id: node.id, window_size: size(textList)} AS metadata\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìã Requ√™te de r√©cup√©ration avec fen√™tre cr√©√©e!\")\n",
    "print(\"üí° Cette requ√™te r√©cup√®re le contexte √©tendu autour de chaque chunk trouv√©\")\n",
    "print(\"üí° Similaire aux fen√™tres de r√©cup√©ration du Lab 5\")\n",
    "\n",
    "# Fonction de test pour la r√©cup√©ration avec fen√™tre\n",
    "def test_window_retrieval():\n",
    "    \"\"\"Test de la r√©cup√©ration avec fen√™tre de contexte\"\"\"\n",
    "    print(f\"\\nüß™ TEST DE LA R√âCUP√âRATION AVEC FEN√äTRE\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    # Test avec une requ√™te simple\n",
    "    test_query = \"\"\"\n",
    "    MATCH (c:Chunk)\n",
    "    WHERE c.text CONTAINS 'Luxembourg'\n",
    "    WITH c, 1.0 as score\n",
    "    LIMIT 1\n",
    "    \n",
    "    MATCH window = (prev:Chunk)-[:NEXT*0..1]->(c)-[:NEXT*0..1]->(next:Chunk)\n",
    "    WHERE (prev IS NULL OR prev.doc_id = c.doc_id)\n",
    "      AND (next IS NULL OR next.doc_id = c.doc_id)\n",
    "    WITH c, score, window as contextWindow \n",
    "      ORDER BY length(window) DESC LIMIT 1\n",
    "    WITH nodes(contextWindow) as chunkList, c, score\n",
    "    RETURN size(chunkList) as window_size,\n",
    "           c.chunk_index as center_chunk,\n",
    "           c.filename as source\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        result = kg.query(test_query)\n",
    "        if result:\n",
    "            window_info = result[0]\n",
    "            print(f\"‚úÖ Test r√©ussi!\")\n",
    "            print(f\"   üìä Taille de fen√™tre: {window_info['window_size']} chunks\")\n",
    "            print(f\"   üéØ Chunk central: index {window_info['center_chunk']}\")\n",
    "            print(f\"   üìÑ Source: {window_info['source']}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Aucun r√©sultat trouv√© pour le test\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur dans le test: {str(e)[:100]}...\")\n",
    "        print(\"üí° La requ√™te sera adapt√©e selon les capacit√©s disponibles\")\n",
    "\n",
    "# Ex√©cuter le test\n",
    "test_window_retrieval()\n",
    "\n",
    "print(f\"\\n‚úÖ Configuration de r√©cup√©ration avec fen√™tre pr√™te!\")\n",
    "print(f\"üí° Peut √™tre utilis√©e avec Neo4jVector.from_existing_index()\")\n",
    "print(f\"üí° Am√©liore le contexte des r√©ponses RAG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "30d045f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ R√âCAPITULATIF FINAL DU KNOWLEDGE GRAPH ENRICHI\n",
      "============================================================\n",
      "üìä N≈íUDS DANS LE KNOWLEDGE GRAPH:\n",
      "   Chunk        : 1,416 n≈ìuds\n",
      "   Entity       : 108 n≈ìuds\n",
      "   Document     : 10 n≈ìuds\n",
      "   TOTAL        : 1,534 n≈ìuds\n",
      "\n",
      "üîó RELATIONS DANS LE KNOWLEDGE GRAPH:\n",
      "   PART_OF      : 1,416 relations\n",
      "   NEXT         : 1,406 relations\n",
      "   RELATED_TO   : 854 relations\n",
      "   SAME_TYPE    : 850 relations\n",
      "   CO_OCCURS    : 423 relations\n",
      "   MENTIONS     : 144 relations\n",
      "   FIRST_CHUNK  : 10 relations\n",
      "   TOTAL        : 5,103 relations\n",
      "\n",
      "üöÄ NOUVELLES CAPACIT√âS AJOUT√âES (inspir√©es de L5):\n",
      "   ‚úÖ üìÑ N≈ìuds Document pour structurer les PDFs\n",
      "   ‚úÖ üîó Relations PART_OF (chunks ‚Üí documents)\n",
      "   ‚úÖ üè∑Ô∏è Relations FIRST_CHUNK (navigation dans documents)\n",
      "   ‚úÖ üîÑ Relations NEXT am√©lior√©es avec APOC\n",
      "   ‚úÖ ü§ù Relations CO_OCCURS entre entit√©s co-occurrentes\n",
      "   ‚úÖ üè∑Ô∏è Relations SAME_TYPE entre entit√©s similaires\n",
      "   ‚úÖ üìç Relations RELATED_TO bas√©es sur la proximit√©\n",
      "   ‚úÖ ü™ü Requ√™tes de fen√™tre de contexte pour RAG\n",
      "   ‚úÖ üéØ Navigation avanc√©e dans la structure du graphe\n",
      "\n",
      "üîç EXEMPLES DE REQU√äTES AVANC√âES DISPONIBLES:\n",
      "   üéØ Fen√™tre de contexte autour d'un chunk\n",
      "   üéØ Navigation Document ‚Üí Chunk ‚Üí Entit√©s\n",
      "   üéØ Entit√©s co-occurrentes fr√©quentes\n",
      "   üéØ Chemins entre entit√©s li√©es\n",
      "   üéØ R√©cup√©ration RAG avec contexte √©tendu\n",
      "\n",
      "üåü KNOWLEDGE GRAPH PR√äT POUR UNE UTILISATION AVANC√âE!\n",
      "   ‚Ä¢ Structure hi√©rarchique: Document ‚Üí Chunk ‚Üí Entity\n",
      "   ‚Ä¢ Relations s√©mantiques entre entit√©s\n",
      "   ‚Ä¢ Navigation contextuelle avec fen√™tres\n",
      "   ‚Ä¢ Compatible avec les techniques avanc√©es de RAG\n",
      "\n",
      "üìà SCH√âMA DU GRAPHE:\n",
      "Node properties:\n",
      "Chunk {chunk_index: INTEGER, text: STRING, id: STRING, text_length: INTEGER, textEmbedding: LIST, filename: STRING, doc_id: STRING, word_count: INTEGER}\n",
      "Entity {source_chunk: INTEGER, confidence: FLOAT, name: STRING, description: STRING, type: STRING, chunk_id: STRING, textEmbedding: LIST}\n",
      "Document {source: STRING, type: STRING, filename: STRING, doc_id: STRING}\n",
      "Relationship properties:\n",
      "MENTIONS {confidence: FLOAT}\n",
      "CO_OCCURS {shared_chunks: INTEGER}\n",
      "SAME_TYPE {type: STRING}\n",
      "RELATED_TO {proximity_count: INTEGER}\n",
      "The relationships:\n",
      "(:Chunk)-[:MENTIONS]->(:Entity)\n",
      "(:Chunk)-[:NEXT]->(:Chunk)\n",
      "(:Chunk)-[:PART_OF]->(:Document)\n",
      "(:Entity)-[:CO_OCCURS]->(:Entity)\n",
      "(:Entity)-[:RELATED_TO]->(:Entity)\n",
      "(:Entity)-[:SAME_TYPE]->(:Entity)\n",
      "(:Document)-[:FIRST_CHUNK]->(:Chunk)\n",
      "üìä N≈íUDS DANS LE KNOWLEDGE GRAPH:\n",
      "   Chunk        : 1,416 n≈ìuds\n",
      "   Entity       : 108 n≈ìuds\n",
      "   Document     : 10 n≈ìuds\n",
      "   TOTAL        : 1,534 n≈ìuds\n",
      "\n",
      "üîó RELATIONS DANS LE KNOWLEDGE GRAPH:\n",
      "   PART_OF      : 1,416 relations\n",
      "   NEXT         : 1,406 relations\n",
      "   RELATED_TO   : 854 relations\n",
      "   SAME_TYPE    : 850 relations\n",
      "   CO_OCCURS    : 423 relations\n",
      "   MENTIONS     : 144 relations\n",
      "   FIRST_CHUNK  : 10 relations\n",
      "   TOTAL        : 5,103 relations\n",
      "\n",
      "üöÄ NOUVELLES CAPACIT√âS AJOUT√âES (inspir√©es de L5):\n",
      "   ‚úÖ üìÑ N≈ìuds Document pour structurer les PDFs\n",
      "   ‚úÖ üîó Relations PART_OF (chunks ‚Üí documents)\n",
      "   ‚úÖ üè∑Ô∏è Relations FIRST_CHUNK (navigation dans documents)\n",
      "   ‚úÖ üîÑ Relations NEXT am√©lior√©es avec APOC\n",
      "   ‚úÖ ü§ù Relations CO_OCCURS entre entit√©s co-occurrentes\n",
      "   ‚úÖ üè∑Ô∏è Relations SAME_TYPE entre entit√©s similaires\n",
      "   ‚úÖ üìç Relations RELATED_TO bas√©es sur la proximit√©\n",
      "   ‚úÖ ü™ü Requ√™tes de fen√™tre de contexte pour RAG\n",
      "   ‚úÖ üéØ Navigation avanc√©e dans la structure du graphe\n",
      "\n",
      "üîç EXEMPLES DE REQU√äTES AVANC√âES DISPONIBLES:\n",
      "   üéØ Fen√™tre de contexte autour d'un chunk\n",
      "   üéØ Navigation Document ‚Üí Chunk ‚Üí Entit√©s\n",
      "   üéØ Entit√©s co-occurrentes fr√©quentes\n",
      "   üéØ Chemins entre entit√©s li√©es\n",
      "   üéØ R√©cup√©ration RAG avec contexte √©tendu\n",
      "\n",
      "üåü KNOWLEDGE GRAPH PR√äT POUR UNE UTILISATION AVANC√âE!\n",
      "   ‚Ä¢ Structure hi√©rarchique: Document ‚Üí Chunk ‚Üí Entity\n",
      "   ‚Ä¢ Relations s√©mantiques entre entit√©s\n",
      "   ‚Ä¢ Navigation contextuelle avec fen√™tres\n",
      "   ‚Ä¢ Compatible avec les techniques avanc√©es de RAG\n",
      "\n",
      "üìà SCH√âMA DU GRAPHE:\n",
      "Node properties:\n",
      "Chunk {chunk_index: INTEGER, text: STRING, id: STRING, text_length: INTEGER, textEmbedding: LIST, filename: STRING, doc_id: STRING, word_count: INTEGER}\n",
      "Entity {source_chunk: INTEGER, confidence: FLOAT, name: STRING, description: STRING, type: STRING, chunk_id: STRING, textEmbedding: LIST}\n",
      "Document {source: STRING, type: STRING, filename: STRING, doc_id: STRING}\n",
      "Relationship properties:\n",
      "MENTIONS {confidence: FLOAT}\n",
      "CO_OCCURS {shared_chunks: INTEGER}\n",
      "SAME_TYPE {type: STRING}\n",
      "RELATED_TO {proximity_count: INTEGER}\n",
      "The relationships:\n",
      "(:Chunk)-[:MENTIONS]->(:Entity)\n",
      "(:Chunk)-[:NEXT]->(:Chunk)\n",
      "(:Chunk)-[:PART_OF]->(:Document)\n",
      "(:Entity)-[:CO_OCCURS]->(:Entity)\n",
      "(:Entity)-[:RELATED_TO]->(:Entity)\n",
      "(:Entity)-[:SAME_TYPE]->(:Entity)\n",
      "(:Document)-[:FIRST_CHUNK]->(:Chunk)\n"
     ]
    }
   ],
   "source": [
    "# üéØ R√âCAPITULATIF FINAL DU KNOWLEDGE GRAPH ENRICHI\n",
    "print(\"üéØ R√âCAPITULATIF FINAL DU KNOWLEDGE GRAPH ENRICHI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Mettre √† jour le sch√©ma\n",
    "kg.refresh_schema()\n",
    "\n",
    "# Statistiques des n≈ìuds\n",
    "node_stats = kg.query(\"\"\"\n",
    "MATCH (n) \n",
    "RETURN labels(n)[0] as nodeType, count(n) as count\n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(\"üìä N≈íUDS DANS LE KNOWLEDGE GRAPH:\")\n",
    "total_nodes = 0\n",
    "for stat in node_stats:\n",
    "    count = stat['count']\n",
    "    total_nodes += count\n",
    "    print(f\"   {stat['nodeType']:12} : {count:,} n≈ìuds\")\n",
    "\n",
    "print(f\"   {'TOTAL':12} : {total_nodes:,} n≈ìuds\")\n",
    "\n",
    "# Statistiques des relations\n",
    "relation_stats = kg.query(\"\"\"\n",
    "MATCH ()-[r]->() \n",
    "RETURN type(r) as relationType, count(r) as count\n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nüîó RELATIONS DANS LE KNOWLEDGE GRAPH:\")\n",
    "total_relations = 0\n",
    "for stat in relation_stats:\n",
    "    count = stat['count']\n",
    "    total_relations += count\n",
    "    print(f\"   {stat['relationType']:12} : {count:,} relations\")\n",
    "\n",
    "print(f\"   {'TOTAL':12} : {total_relations:,} relations\")\n",
    "\n",
    "# Capacit√©s ajout√©es depuis L5\n",
    "print(f\"\\nüöÄ NOUVELLES CAPACIT√âS AJOUT√âES (inspir√©es de L5):\")\n",
    "capabilities = [\n",
    "    \"üìÑ N≈ìuds Document pour structurer les PDFs\",\n",
    "    \"üîó Relations PART_OF (chunks ‚Üí documents)\",\n",
    "    \"üè∑Ô∏è Relations FIRST_CHUNK (navigation dans documents)\",\n",
    "    \"üîÑ Relations NEXT am√©lior√©es avec APOC\",\n",
    "    \"ü§ù Relations CO_OCCURS entre entit√©s co-occurrentes\",\n",
    "    \"üè∑Ô∏è Relations SAME_TYPE entre entit√©s similaires\",\n",
    "    \"üìç Relations RELATED_TO bas√©es sur la proximit√©\",\n",
    "    \"ü™ü Requ√™tes de fen√™tre de contexte pour RAG\",\n",
    "    \"üéØ Navigation avanc√©e dans la structure du graphe\"\n",
    "]\n",
    "\n",
    "for capability in capabilities:\n",
    "    print(f\"   ‚úÖ {capability}\")\n",
    "\n",
    "# Exemples de requ√™tes avanc√©es disponibles\n",
    "print(f\"\\nüîç EXEMPLES DE REQU√äTES AVANC√âES DISPONIBLES:\")\n",
    "queries = [\n",
    "    \"Fen√™tre de contexte autour d'un chunk\",\n",
    "    \"Navigation Document ‚Üí Chunk ‚Üí Entit√©s\", \n",
    "    \"Entit√©s co-occurrentes fr√©quentes\",\n",
    "    \"Chemins entre entit√©s li√©es\",\n",
    "    \"R√©cup√©ration RAG avec contexte √©tendu\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"   üéØ {query}\")\n",
    "\n",
    "print(f\"\\nüåü KNOWLEDGE GRAPH PR√äT POUR UNE UTILISATION AVANC√âE!\")\n",
    "print(f\"   ‚Ä¢ Structure hi√©rarchique: Document ‚Üí Chunk ‚Üí Entity\")\n",
    "print(f\"   ‚Ä¢ Relations s√©mantiques entre entit√©s\")\n",
    "print(f\"   ‚Ä¢ Navigation contextuelle avec fen√™tres\")\n",
    "print(f\"   ‚Ä¢ Compatible avec les techniques avanc√©es de RAG\")\n",
    "\n",
    "print(f\"\\nüìà SCH√âMA DU GRAPHE:\")\n",
    "print(kg.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b377f3a1",
   "metadata": {},
   "source": [
    "## Visualisation du Knowledge Graph\n",
    "\n",
    "Maintenant, visualisons notre Knowledge Graph directement dans le notebook avec plusieurs m√©thodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "61d291c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function. ('id' has been replaced by 'elementId or consider using an application-generated id')} {position: line: 3, column: 12, offset: 27} for query: '\\n    MATCH (n) \\n    RETURN id(n) as node_id, labels(n)[0] as label, \\n           n.name as name, n.type as type, n.id as chunk_id\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function. ('id' has been replaced by 'elementId or consider using an application-generated id')} {position: line: 3, column: 12, offset: 36} for query: '\\n    MATCH (a)-[r]->(b) \\n    RETURN id(a) as source, id(b) as target, type(r) as relation_type,\\n           r.confidence as confidence\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function. ('id' has been replaced by 'elementId or consider using an application-generated id')} {position: line: 3, column: 29, offset: 53} for query: '\\n    MATCH (a)-[r]->(b) \\n    RETURN id(a) as source, id(b) as target, type(r) as relation_type,\\n           r.confidence as confidence\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function. ('id' has been replaced by 'elementId or consider using an application-generated id')} {position: line: 3, column: 12, offset: 36} for query: '\\n    MATCH (a)-[r]->(b) \\n    RETURN id(a) as source, id(b) as target, type(r) as relation_type,\\n           r.confidence as confidence\\n    '\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated function. ('id' has been replaced by 'elementId or consider using an application-generated id')} {position: line: 3, column: 29, offset: 53} for query: '\\n    MATCH (a)-[r]->(b) \\n    RETURN id(a) as source, id(b) as target, type(r) as relation_type,\\n           r.confidence as confidence\\n    '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Donn√©es r√©cup√©r√©es:\n",
      "   N≈ìuds: 1534\n",
      "   Relations: 5103\n"
     ]
    }
   ],
   "source": [
    "# Fonction pour r√©cup√©rer les donn√©es du graphe\n",
    "def get_graph_data_from_neo4j():\n",
    "    \"\"\"R√©cup√®re les donn√©es du graphe Neo4j pour visualisation\"\"\"\n",
    "    \n",
    "    # R√©cup√©rer tous les n≈ìuds\n",
    "    nodes_query = \"\"\"\n",
    "    MATCH (n) \n",
    "    RETURN id(n) as node_id, labels(n)[0] as label, \n",
    "           n.name as name, n.type as type, n.id as chunk_id\n",
    "    \"\"\"\n",
    "    nodes_data = kg.query(nodes_query)\n",
    "    \n",
    "    # R√©cup√©rer toutes les relations\n",
    "    edges_query = \"\"\"\n",
    "    MATCH (a)-[r]->(b) \n",
    "    RETURN id(a) as source, id(b) as target, type(r) as relation_type,\n",
    "           r.confidence as confidence\n",
    "    \"\"\"\n",
    "    edges_data = kg.query(edges_query)\n",
    "    \n",
    "    return nodes_data, edges_data\n",
    "\n",
    "# R√©cup√©rer les donn√©es\n",
    "nodes_data, edges_data = get_graph_data_from_neo4j()\n",
    "\n",
    "print(f\"üìä Donn√©es r√©cup√©r√©es:\")\n",
    "print(f\"   N≈ìuds: {len(nodes_data)}\")\n",
    "print(f\"   Relations: {len(edges_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda364e4",
   "metadata": {},
   "source": [
    "## Visualisation avanc√©e avec yFiles Jupyter Graphs pour Neo4j\n",
    "\n",
    "yFiles pour Neo4j offre une int√©gration directe avec la base de donn√©es pour des visualisations tr√®s avanc√©es avec des layouts automatiques et une interactivit√© pouss√©e."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee4731",
   "metadata": {},
   "source": [
    "### Cr√©ation du widget yFiles Neo4j avec requ√™te Cypher directe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "30e4e0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(\n",
    "    uri = NEO4J_URI, \n",
    "    auth = (NEO4J_USERNAME, NEO4J_PASSWORD), \n",
    "    database = NEO4J_DATABASE\n",
    "    )\n",
    "g = Neo4jGraphWidget(driver)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e026539",
   "metadata": {},
   "source": [
    "### Visualisation du Knowledge Graph avec requ√™te Cypher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "3256ce1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6138337421cf4e2189ce0f09b52332c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "GraphWidget(layout=Layout(height='800px', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ Knowledge Graph affich√©!\n",
      "üîç Vous pouvez interagir avec le graphe:\n",
      "   ‚Ä¢ Zoom avec la molette\n",
      "   ‚Ä¢ D√©placer les n≈ìuds\n",
      "   ‚Ä¢ Cliquer pour s√©lectionner\n",
      "   ‚Ä¢ Layouts automatiques disponibles\n"
     ]
    }
   ],
   "source": [
    "# Afficher le Knowledge Graph avec une requ√™te Cypher simple\n",
    "# Exactement comme dans votre exemple\n",
    "g.show_cypher(\"MATCH (s)-[r]->(t) RETURN s,r,t\")\n",
    "\n",
    "print(\"üéâ Knowledge Graph affich√©!\")\n",
    "print(\"üîç Vous pouvez interagir avec le graphe:\")\n",
    "print(\"   ‚Ä¢ Zoom avec la molette\")\n",
    "print(\"   ‚Ä¢ D√©placer les n≈ìuds\")\n",
    "print(\"   ‚Ä¢ Cliquer pour s√©lectionner\")\n",
    "print(\"   ‚Ä¢ Layouts automatiques disponibles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "da900515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ F√âLICITATIONS ! Votre Knowledge Graph est op√©rationnel\n",
      "============================================================\n",
      "‚úÖ √âTAPES ACCOMPLIES:\n",
      "   1. üìÑ Extraction et chunking du PDF\n",
      "   2. ü§ñ Extraction d'entit√©s avec OpenAI GPT-3.5\n",
      "   3. üîó G√©n√©ration d'embeddings OpenAI\n",
      "   4. üóÑÔ∏è Cr√©ation du Knowledge Graph dans Neo4j\n",
      "   5. üìä Visualisation avec yFiles Neo4j (connexion directe)\n",
      "\n",
      "üìä STATISTIQUES DU KNOWLEDGE GRAPH:\n",
      "   üìö Chunks de texte: 1416\n",
      "   üè∑Ô∏è Entit√©s extraites: 108\n",
      "   üîó Relations MENTIONS: 144\n",
      "\n",
      "üõ†Ô∏è OUTILS UTILIS√âS:\n",
      "   ‚Ä¢ Neo4j (base de donn√©es graphe)\n",
      "   ‚Ä¢ OpenAI GPT-3.5-turbo (extraction d'entit√©s)\n",
      "   ‚Ä¢ OpenAI text-embedding-3-small (embeddings)\n",
      "   ‚Ä¢ yFiles Jupyter Graphs pour Neo4j (visualisation)\n",
      "   ‚Ä¢ LangChain (orchestration)\n",
      "\n",
      "üéØ UTILISATION:\n",
      "   ‚Ä¢ Ex√©cutez: g.show_cypher('VOTRE_REQUETE_CYPHER')\n",
      "   ‚Ä¢ Explorez les entit√©s par type\n",
      "   ‚Ä¢ Analysez les relations s√©mantiques\n",
      "   ‚Ä¢ Utilisez les layouts automatiques de yFiles\n",
      "\n",
      "üöÄ PROCHAINES √âTAPES SUGG√âR√âES:\n",
      "   1. Ajoutez d'autres documents pour enrichir le graphe\n",
      "   2. Impl√©mentez des requ√™tes de recherche s√©mantique\n",
      "   3. Cr√©ez des vues personnalis√©es avec Cypher\n",
      "   4. Exploitez les embeddings pour la similarit√©\n",
      "\n",
      "üé® VISUALISATION INTERACTIVE PR√äTE!\n",
      "Utilisez les cellules ci-dessus pour explorer votre Knowledge Graph avec yFiles.\n",
      "\n",
      "üåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåü\n",
      "   KNOWLEDGE GRAPH RAG OP√âRATIONNEL\n",
      "üåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåü\n",
      "\n",
      "üìä STATISTIQUES DU KNOWLEDGE GRAPH:\n",
      "   üìö Chunks de texte: 1416\n",
      "   üè∑Ô∏è Entit√©s extraites: 108\n",
      "   üîó Relations MENTIONS: 144\n",
      "\n",
      "üõ†Ô∏è OUTILS UTILIS√âS:\n",
      "   ‚Ä¢ Neo4j (base de donn√©es graphe)\n",
      "   ‚Ä¢ OpenAI GPT-3.5-turbo (extraction d'entit√©s)\n",
      "   ‚Ä¢ OpenAI text-embedding-3-small (embeddings)\n",
      "   ‚Ä¢ yFiles Jupyter Graphs pour Neo4j (visualisation)\n",
      "   ‚Ä¢ LangChain (orchestration)\n",
      "\n",
      "üéØ UTILISATION:\n",
      "   ‚Ä¢ Ex√©cutez: g.show_cypher('VOTRE_REQUETE_CYPHER')\n",
      "   ‚Ä¢ Explorez les entit√©s par type\n",
      "   ‚Ä¢ Analysez les relations s√©mantiques\n",
      "   ‚Ä¢ Utilisez les layouts automatiques de yFiles\n",
      "\n",
      "üöÄ PROCHAINES √âTAPES SUGG√âR√âES:\n",
      "   1. Ajoutez d'autres documents pour enrichir le graphe\n",
      "   2. Impl√©mentez des requ√™tes de recherche s√©mantique\n",
      "   3. Cr√©ez des vues personnalis√©es avec Cypher\n",
      "   4. Exploitez les embeddings pour la similarit√©\n",
      "\n",
      "üé® VISUALISATION INTERACTIVE PR√äTE!\n",
      "Utilisez les cellules ci-dessus pour explorer votre Knowledge Graph avec yFiles.\n",
      "\n",
      "üåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåü\n",
      "   KNOWLEDGE GRAPH RAG OP√âRATIONNEL\n",
      "üåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåü\n"
     ]
    }
   ],
   "source": [
    "# üéâ PIPELINE KNOWLEDGE GRAPH COMPLET !\n",
    "print(\"üéâ F√âLICITATIONS ! Votre Knowledge Graph est op√©rationnel\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"‚úÖ √âTAPES ACCOMPLIES:\")\n",
    "print(\"   1. üìÑ Extraction et chunking du PDF\")\n",
    "print(\"   2. ü§ñ Extraction d'entit√©s avec OpenAI GPT-3.5\")\n",
    "print(\"   3. üîó G√©n√©ration d'embeddings OpenAI\")\n",
    "print(\"   4. üóÑÔ∏è Cr√©ation du Knowledge Graph dans Neo4j\")\n",
    "print(\"   5. üìä Visualisation avec yFiles Neo4j (connexion directe)\")\n",
    "\n",
    "# Statistiques finales\n",
    "with driver.session() as session:\n",
    "    chunk_count = session.run(\"MATCH (c:Chunk) RETURN count(c) as count\").single()[\"count\"]\n",
    "    entity_count = session.run(\"MATCH (e:Entity) RETURN count(e) as count\").single()[\"count\"]\n",
    "    mentions_count = session.run(\"MATCH ()-[r:MENTIONS]->() RETURN count(r) as count\").single()[\"count\"]\n",
    "\n",
    "print(f\"\\nüìä STATISTIQUES DU KNOWLEDGE GRAPH:\")\n",
    "print(f\"   üìö Chunks de texte: {chunk_count}\")\n",
    "print(f\"   üè∑Ô∏è Entit√©s extraites: {entity_count}\")\n",
    "print(f\"   üîó Relations MENTIONS: {mentions_count}\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è OUTILS UTILIS√âS:\")\n",
    "print(f\"   ‚Ä¢ Neo4j (base de donn√©es graphe)\")\n",
    "print(f\"   ‚Ä¢ OpenAI GPT-3.5-turbo (extraction d'entit√©s)\")\n",
    "print(f\"   ‚Ä¢ OpenAI text-embedding-3-small (embeddings)\")\n",
    "print(f\"   ‚Ä¢ yFiles Jupyter Graphs pour Neo4j (visualisation)\")\n",
    "print(f\"   ‚Ä¢ LangChain (orchestration)\")\n",
    "\n",
    "print(f\"\\nüéØ UTILISATION:\")\n",
    "print(f\"   ‚Ä¢ Ex√©cutez: g.show_cypher('VOTRE_REQUETE_CYPHER')\")\n",
    "print(f\"   ‚Ä¢ Explorez les entit√©s par type\")\n",
    "print(f\"   ‚Ä¢ Analysez les relations s√©mantiques\")\n",
    "print(f\"   ‚Ä¢ Utilisez les layouts automatiques de yFiles\")\n",
    "\n",
    "print(f\"\\nüöÄ PROCHAINES √âTAPES SUGG√âR√âES:\")\n",
    "print(f\"   1. Ajoutez d'autres documents pour enrichir le graphe\")\n",
    "print(f\"   2. Impl√©mentez des requ√™tes de recherche s√©mantique\")\n",
    "print(f\"   3. Cr√©ez des vues personnalis√©es avec Cypher\")\n",
    "print(f\"   4. Exploitez les embeddings pour la similarit√©\")\n",
    "\n",
    "print(f\"\\nüé® VISUALISATION INTERACTIVE PR√äTE!\")\n",
    "print(f\"Utilisez les cellules ci-dessus pour explorer votre Knowledge Graph avec yFiles.\")\n",
    "\n",
    "# Message de fin\n",
    "print(f\"\\n\" + \"üåü\" * 20)\n",
    "print(f\"   KNOWLEDGE GRAPH RAG OP√âRATIONNEL\")\n",
    "print(f\"üåü\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "25f2fe64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuration Neo4j Vector Store:\n",
      "   Index: GrahRAG\n",
      "   Node Label: Chunk\n",
      "   Text Property: text\n",
      "   Embedding Property: textEmbedding\n",
      "‚úÖ Neo4j Vector Store configur√© avec succ√®s\n",
      "‚úÖ Neo4j Vector Store configur√© avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# üîß CONFIGURATION CORRIG√âE POUR NEO4J VECTOR STORE\n",
    "# Utiliser le bon nom d'index qui existe vraiment dans votre base\n",
    "CORRECT_VECTOR_INDEX_NAME = 'GrahRAG'  # Le vrai nom de votre index\n",
    "\n",
    "print(f\"üîß Configuration Neo4j Vector Store:\")\n",
    "print(f\"   Index: {CORRECT_VECTOR_INDEX_NAME}\")\n",
    "print(f\"   Node Label: {VECTOR_NODE_LABEL}\")\n",
    "print(f\"   Text Property: {VECTOR_SOURCE_PROPERTY}\")\n",
    "print(f\"   Embedding Property: {VECTOR_EMBEDDING_PROPERTY}\")\n",
    "\n",
    "try:\n",
    "    neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
    "        embedding=OpenAIEmbeddings(),\n",
    "        url=NEO4J_URI,\n",
    "        username=NEO4J_USERNAME,\n",
    "        password=NEO4J_PASSWORD,\n",
    "        index_name=CORRECT_VECTOR_INDEX_NAME,  # Utiliser le bon nom\n",
    "        node_label=VECTOR_NODE_LABEL,\n",
    "        text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
    "        embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
    "    )\n",
    "    print(\"‚úÖ Neo4j Vector Store configur√© avec succ√®s\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur configuration Neo4j Vector Store: {str(e)[:200]}...\")\n",
    "    print(\"üí° V√©rification des param√®tres:\")\n",
    "    \n",
    "    # V√©rifier l'index\n",
    "    indexes = kg.query(\"SHOW INDEXES\")\n",
    "    print(f\"   Indexes disponibles: {[idx['name'] for idx in indexes]}\")\n",
    "    \n",
    "    # V√©rifier les n≈ìuds\n",
    "    nodes = kg.query(\"MATCH (n:Chunk) RETURN count(n) as count\")\n",
    "    print(f\"   N≈ìuds Chunk: {nodes[0]['count'] if nodes else 0}\")\n",
    "    \n",
    "    neo4j_vector_store = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "ecec606d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Retriever configur√© avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# üîß CR√âATION DU RETRIEVER AVEC GESTION D'ERREUR\n",
    "if neo4j_vector_store is not None:\n",
    "    try:\n",
    "        retriever = neo4j_vector_store.as_retriever()\n",
    "        print(\"‚úÖ Retriever configur√© avec succ√®s\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur cr√©ation retriever: {str(e)[:200]}...\")\n",
    "        retriever = None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Vector store non disponible - retriever non cr√©√©\")\n",
    "    retriever = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "6af2a433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cha√Æne RAG configur√©e avec succ√®s\n"
     ]
    }
   ],
   "source": [
    "# üîß CR√âATION DE LA CHA√éNE RAG AVEC GESTION D'ERREUR\n",
    "if retriever is not None:\n",
    "    try:\n",
    "        chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "            ChatOpenAI(temperature=0), \n",
    "            chain_type=\"stuff\", \n",
    "            retriever=retriever\n",
    "        )\n",
    "        print(\"‚úÖ Cha√Æne RAG configur√©e avec succ√®s\")\n",
    "        chain_available = True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur cr√©ation cha√Æne RAG: {str(e)[:200]}...\")\n",
    "        chain = None\n",
    "        chain_available = False\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Retriever non disponible - cha√Æne RAG non cr√©√©e\")\n",
    "    chain = None\n",
    "    chain_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "8db93dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonctions RAG am√©lior√©es cr√©√©es!\n",
      "üí° Utilisez prettychain('votre question') pour tester\n",
      "üí° Utilisez test_rag_system() pour un test complet\n"
     ]
    }
   ],
   "source": [
    "# ü§ñ FONCTION RAG AM√âLIOR√âE AVEC FALLBACK\n",
    "def prettychain(question: str) -> str:\n",
    "    \"\"\"Fonction RAG robuste avec fallback sur recherche vectorielle\"\"\"\n",
    "    \n",
    "    print(f\"ü§î Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # M√©thode 1: Essayer la cha√Æne RAG standard\n",
    "    if chain_available and chain is not None:\n",
    "        try:\n",
    "            print(\"üîÑ Utilisation de la cha√Æne RAG standard...\")\n",
    "            response = chain({\"question\": question}, return_only_outputs=True)\n",
    "            answer = response.get('answer', 'Pas de r√©ponse')\n",
    "            sources = response.get('sources', 'Pas de sources')\n",
    "            \n",
    "            print(\"‚úÖ R√©ponse RAG:\")\n",
    "            print(textwrap.fill(answer, 80))\n",
    "            print(f\"\\nüìö Sources: {sources}\")\n",
    "            return answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur cha√Æne RAG: {str(e)[:100]}...\")\n",
    "            print(\"üîÑ Basculement vers recherche vectorielle...\")\n",
    "    \n",
    "    # M√©thode 2: Fallback avec recherche vectorielle directe\n",
    "    try:\n",
    "        print(\"üîç Utilisation de la recherche vectorielle directe...\")\n",
    "        results = neo4j_vector_search_robust(question, top_k=3)\n",
    "        \n",
    "        if results:\n",
    "            # Construire une r√©ponse √† partir des r√©sultats\n",
    "            context_parts = []\n",
    "            sources = []\n",
    "            \n",
    "            for i, result in enumerate(results[:3]):\n",
    "                context_parts.append(result['text'])\n",
    "                sources.append(result['source'])\n",
    "            \n",
    "            context = \"\\n\\n\".join(context_parts)\n",
    "            unique_sources = list(set(sources))\n",
    "            \n",
    "            # Utiliser OpenAI pour g√©n√©rer une r√©ponse bas√©e sur le contexte\n",
    "            from langchain_openai import ChatOpenAI\n",
    "            llm = ChatOpenAI(temperature=0)\n",
    "            \n",
    "            prompt = f\"\"\"Bas√© sur le contexte suivant, r√©ponds √† la question: \"{question}\"\n",
    "            \n",
    "Contexte:\n",
    "{context}\n",
    "\n",
    "R√©ponds de mani√®re concise et factuelle en fran√ßais.\"\"\"\n",
    "            \n",
    "            ai_response = llm.invoke(prompt)\n",
    "            answer = ai_response.content\n",
    "            \n",
    "            print(\"‚úÖ R√©ponse bas√©e sur recherche vectorielle:\")\n",
    "            print(textwrap.fill(answer, 80))\n",
    "            print(f\"\\nüìö Sources: {', '.join(unique_sources)}\")\n",
    "            return answer\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Aucun r√©sultat trouv√© dans la recherche vectorielle\")\n",
    "            return \"D√©sol√©, je n'ai pas trouv√© d'informations pertinentes pour cette question.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur recherche vectorielle: {str(e)[:100]}...\")\n",
    "        return \"Erreur lors de la recherche d'informations.\"\n",
    "\n",
    "# üß™ FONCTION DE TEST SIMPLE\n",
    "def test_rag_system():\n",
    "    \"\"\"Test du syst√®me RAG\"\"\"\n",
    "    \n",
    "    print(\"üß™ TEST DU SYST√àME RAG\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    test_questions = [\n",
    "        \"c'est quoi Luxchatgov\",\n",
    "        \"Luxembourg\",\n",
    "        \"What technologies are mentioned?\"\n",
    "    ]\n",
    "    \n",
    "    for question in test_questions:\n",
    "        print(f\"\\nüîç Test: {question}\")\n",
    "        result = prettychain(question)\n",
    "        print(\"=\" * 40)\n",
    "\n",
    "print(\"‚úÖ Fonctions RAG am√©lior√©es cr√©√©es!\")\n",
    "print(\"üí° Utilisez prettychain('votre question') pour tester\")\n",
    "print(\"üí° Utilisez test_rag_system() pour un test complet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73024ea0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "e4cb4c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§î Question: c'est quoi Luxchatgov\n",
      "--------------------------------------------------\n",
      "üîÑ Utilisation de la cha√Æne RAG standard...\n",
      "‚ùå Erreur cha√Æne RAG: Document prompt requires documents to have metadata variables: ['source']. Received document with mi...\n",
      "üîÑ Basculement vers recherche vectorielle...\n",
      "üîç Utilisation de la recherche vectorielle directe...\n",
      "üîç Recherche pour: 'c'est quoi Luxchatgov'\n",
      "‚ùå Erreur cha√Æne RAG: Document prompt requires documents to have metadata variables: ['source']. Received document with mi...\n",
      "üîÑ Basculement vers recherche vectorielle...\n",
      "üîç Utilisation de la recherche vectorielle directe...\n",
      "üîç Recherche pour: 'c'est quoi Luxchatgov'\n",
      "‚úÖ Recherche r√©ussie: 3 r√©sultats trouv√©s\n",
      "   1. Score: 0.7545 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Appel √† projets Tech-in-GOV ...........................................................................\n",
      "   2. Score: 0.7370 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Luxchat4Gov ...........................................................................................\n",
      "   3. Score: 0.7319 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: MyGuichet.lu ..........................................................................................\n",
      "‚úÖ Recherche r√©ussie: 3 r√©sultats trouv√©s\n",
      "   1. Score: 0.7545 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Appel √† projets Tech-in-GOV ...........................................................................\n",
      "   2. Score: 0.7370 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Luxchat4Gov ...........................................................................................\n",
      "   3. Score: 0.7319 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: MyGuichet.lu ..........................................................................................\n",
      "‚úÖ R√©ponse bas√©e sur recherche vectorielle:\n",
      "Luxchat4Gov est un projet li√© √† la digitalisation de l'administration publique\n",
      "au Luxembourg.\n",
      "\n",
      "üìö Sources: rapport-activite-2024-fin.pdf\n",
      "‚úÖ R√©ponse bas√©e sur recherche vectorielle:\n",
      "Luxchat4Gov est un projet li√© √† la digitalisation de l'administration publique\n",
      "au Luxembourg.\n",
      "\n",
      "üìö Sources: rapport-activite-2024-fin.pdf\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Luxchat4Gov est un projet li√© √† la digitalisation de l'administration publique au Luxembourg.\""
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prettychain(\"c'est quoi Luxchatgov\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e9e7500f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Fonction prettychain robuste cr√©√©e!\n",
      "üí° Cette version g√®re les m√©tadonn√©es source manquantes\n",
      "üí° Elle utilise la recherche vectorielle comme m√©thode principale\n"
     ]
    }
   ],
   "source": [
    "# üõ†Ô∏è FONCTION PRETTYCHAIN ROBUSTE - CORRIG√âE\n",
    "def prettychain(question: str) -> str:\n",
    "    \"\"\"Fonction RAG robuste avec gestion des m√©tadonn√©es source manquantes\"\"\"\n",
    "    \n",
    "    print(f\"ü§î Question: {question}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # D'abord essayer la recherche vectorielle directe qui fonctionne\n",
    "    try:\n",
    "        print(\"üîç Utilisation de la recherche vectorielle directe...\")\n",
    "        results = neo4j_vector_search_robust(question, top_k=3)\n",
    "        \n",
    "        if results:\n",
    "            # Construire une r√©ponse √† partir des r√©sultats\n",
    "            context_parts = []\n",
    "            sources = []\n",
    "            \n",
    "            for i, result in enumerate(results[:3]):\n",
    "                context_parts.append(result['text'])\n",
    "                sources.append(result['source'])\n",
    "            \n",
    "            context = \"\\n\\n\".join(context_parts)\n",
    "            unique_sources = list(set(sources))\n",
    "            \n",
    "            # Utiliser OpenAI pour g√©n√©rer une r√©ponse bas√©e sur le contexte\n",
    "            from langchain_openai import ChatOpenAI\n",
    "            llm = ChatOpenAI(temperature=0)\n",
    "            \n",
    "            prompt = f\"\"\"Bas√© sur le contexte suivant, r√©ponds √† la question: \"{question}\"\n",
    "            \n",
    "Contexte:\n",
    "{context}\n",
    "\n",
    "R√©ponds de mani√®re concise et factuelle en fran√ßais.\"\"\"\n",
    "            \n",
    "            ai_response = llm.invoke(prompt)\n",
    "            answer = ai_response.content\n",
    "            \n",
    "            print(\"‚úÖ R√©ponse bas√©e sur recherche vectorielle:\")\n",
    "            print(textwrap.fill(answer, 80))\n",
    "            print(f\"\\nüìö Sources: {', '.join(unique_sources)}\")\n",
    "            return answer\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Aucun r√©sultat trouv√© dans la recherche vectorielle\")\n",
    "            return \"D√©sol√©, je n'ai pas trouv√© d'informations pertinentes pour cette question.\"\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur recherche vectorielle: {str(e)[:100]}...\")\n",
    "        \n",
    "        # Fallback: essayer la cha√Æne RAG avec correction des m√©tadonn√©es\n",
    "        try:\n",
    "            print(\"üîÑ Tentative avec cha√Æne RAG corrig√©e...\")\n",
    "            \n",
    "            # R√©cup√©rer les documents via le retriever\n",
    "            docs = retriever.get_relevant_documents(question)\n",
    "            \n",
    "            # Corriger les m√©tadonn√©es manquantes\n",
    "            for doc in docs:\n",
    "                if 'source' not in doc.metadata:\n",
    "                    # Utiliser le nom de fichier si disponible, sinon valeur par d√©faut\n",
    "                    if hasattr(doc, 'page_content') and len(doc.page_content) > 0:\n",
    "                        doc.metadata['source'] = \"Knowledge Graph\"\n",
    "                    else:\n",
    "                        doc.metadata['source'] = \"Unknown\"\n",
    "            \n",
    "            # Utiliser la cha√Æne avec les documents corrig√©s\n",
    "            response = chain({\"question\": question}, return_only_outputs=True)\n",
    "            answer = response.get('answer', 'Pas de r√©ponse')\n",
    "            sources = response.get('sources', 'Pas de sources')\n",
    "            \n",
    "            print(\"‚úÖ R√©ponse RAG corrig√©e:\")\n",
    "            print(textwrap.fill(answer, 80))\n",
    "            print(f\"\\nüìö Sources: {sources}\")\n",
    "            return answer\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Erreur cha√Æne RAG: {str(e2)[:100]}...\")\n",
    "            return \"Erreur lors de la recherche d'informations.\"\n",
    "\n",
    "print(\"‚úÖ Fonction prettychain robuste cr√©√©e!\")\n",
    "print(\"üí° Cette version g√®re les m√©tadonn√©es source manquantes\")\n",
    "print(\"üí° Elle utilise la recherche vectorielle comme m√©thode principale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "efcd366d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ Test de la fonction prettychain corrig√©e:\n",
      "==================================================\n",
      "ü§î Question: c'est quoi Luxchatgov\n",
      "--------------------------------------------------\n",
      "üîç Utilisation de la recherche vectorielle directe...\n",
      "üîç Recherche pour: 'c'est quoi Luxchatgov'\n",
      "‚úÖ Recherche r√©ussie: 3 r√©sultats trouv√©s\n",
      "   1. Score: 0.7544 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Appel √† projets Tech-in-GOV ...........................................................................\n",
      "   2. Score: 0.7370 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Luxchat4Gov ...........................................................................................\n",
      "   3. Score: 0.7319 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: MyGuichet.lu ..........................................................................................\n",
      "‚úÖ Recherche r√©ussie: 3 r√©sultats trouv√©s\n",
      "   1. Score: 0.7544 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Appel √† projets Tech-in-GOV ...........................................................................\n",
      "   2. Score: 0.7370 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: Luxchat4Gov ...........................................................................................\n",
      "   3. Score: 0.7319 | Source: rapport-activite-2024-fin.pdf\n",
      "      Text: MyGuichet.lu ..........................................................................................\n",
      "‚úÖ R√©ponse bas√©e sur recherche vectorielle:\n",
      "Luxchat4Gov est un service de messagerie s√©curis√© destin√© aux administrations\n",
      "publiques au Luxembourg.\n",
      "\n",
      "üìö Sources: rapport-activite-2024-fin.pdf\n",
      "‚úÖ R√©ponse bas√©e sur recherche vectorielle:\n",
      "Luxchat4Gov est un service de messagerie s√©curis√© destin√© aux administrations\n",
      "publiques au Luxembourg.\n",
      "\n",
      "üìö Sources: rapport-activite-2024-fin.pdf\n"
     ]
    }
   ],
   "source": [
    "# üß™ TEST DE LA FONCTION PRETTYCHAIN CORRIG√âE\n",
    "print(\"üß™ Test de la fonction prettychain corrig√©e:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test avec la m√™me question qui causait l'erreur\n",
    "test_result = prettychain(\"c'est quoi Luxchatgov\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
